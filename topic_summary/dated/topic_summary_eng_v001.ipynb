{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding=UTF-8\n",
    "from __future__ import division\n",
    "import re\n",
    "\n",
    "# This is a naive text summarization algorithm\n",
    "# Created by Shlomi Babluki\n",
    "# April, 2013\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SummaryTool(object):\n",
    "\n",
    "    # Naive method for splitting a text into sentences\n",
    "    def split_content_to_sentences(self, content):\n",
    "        content = content.replace(\"\\n\", \". \")\n",
    "        return content.split(\". \")\n",
    "\n",
    "    # Naive method for splitting a text into paragraphs\n",
    "    def split_content_to_paragraphs(self, content):\n",
    "        return content.split(\"\\n\\n\")\n",
    "\n",
    "    # Caculate the intersection between 2 sentences\n",
    "    def sentences_intersection(self, sent1, sent2):\n",
    "\n",
    "        # split the sentence into words/tokens\n",
    "        s1 = set(sent1.split(\" \"))\n",
    "        s2 = set(sent2.split(\" \"))\n",
    "\n",
    "        # If there is not intersection, just return 0\n",
    "        if (len(s1) + len(s2)) == 0:\n",
    "            return 0\n",
    "\n",
    "        # We normalize the result by the average number of words\n",
    "        return len(s1.intersection(s2)) / ((len(s1) + len(s2)) / 2)\n",
    "\n",
    "    # Format a sentence - remove all non-alphbetic chars from the sentence\n",
    "    # We'll use the formatted sentence as a key in our sentences dictionary\n",
    "    def format_sentence(self, sentence):\n",
    "        sentence = re.sub(r'\\W+', '', sentence)\n",
    "        return sentence\n",
    "\n",
    "    # Convert the content into a dictionary <K, V>\n",
    "    # k = The formatted sentence\n",
    "    # V = The rank of the sentence\n",
    "    def get_senteces_ranks(self, content):\n",
    "\n",
    "        # Split the content into sentences\n",
    "        sentences = self.split_content_to_sentences(content)\n",
    "\n",
    "        # Calculate the intersection of every two sentences\n",
    "        n = len(sentences)\n",
    "        # [Sam python 2.7 -> 3.4] values = [[0 for x in xrange(n)] for x in xrange(n)]\n",
    "        values = [[0 for x in range(n)] for x in range(n)]\n",
    "        for i in range(0, n):\n",
    "            for j in range(0, n):\n",
    "                values[i][j] = self.sentences_intersection(sentences[i], sentences[j])\n",
    "\n",
    "        # Build the sentences dictionary\n",
    "        # The score of a sentences is the sum of all its intersection\n",
    "        sentences_dic = {}\n",
    "        for i in range(0, n):\n",
    "            score = 0\n",
    "            for j in range(0, n):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                score += values[i][j]\n",
    "            sentences_dic[self.format_sentence(sentences[i])] = score\n",
    "        return sentences_dic\n",
    "\n",
    "    # Return the best sentence in a paragraph\n",
    "    def get_best_sentence(self, paragraph, sentences_dic):\n",
    "\n",
    "        # Split the paragraph into sentences\n",
    "        sentences = self.split_content_to_sentences(paragraph)\n",
    "\n",
    "        # Ignore short paragraphs\n",
    "        if len(sentences) < 2:\n",
    "            return \"\"\n",
    "\n",
    "        # Get the best sentence according to the sentences dictionary\n",
    "        best_sentence = \"\"\n",
    "        max_value = 0\n",
    "        for s in sentences:\n",
    "            strip_s = self.format_sentence(s)\n",
    "            if strip_s:\n",
    "                if sentences_dic[strip_s] > max_value:\n",
    "                    max_value = sentences_dic[strip_s]\n",
    "                    best_sentence = s\n",
    "\n",
    "        return best_sentence\n",
    "\n",
    "    # Build the summary\n",
    "    def get_summary(self, title, content, sentences_dic):\n",
    "\n",
    "        # Split the content into paragraphs\n",
    "        paragraphs = self.split_content_to_paragraphs(content)\n",
    "\n",
    "        # Add the title\n",
    "        summary = []\n",
    "        summary.append(title.strip())\n",
    "        summary.append(\"\")\n",
    "\n",
    "        # Add the best sentence from each paragraph\n",
    "        for p in paragraphs:\n",
    "            sentence = self.get_best_sentence(p, sentences_dic).strip()\n",
    "            if sentence:\n",
    "                summary.append(sentence)\n",
    "\n",
    "        return (\"\\n\").join(summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Main method, just run \"python summary_tool.py\"\n",
    "# def main():\n",
    "\n",
    "    # Demo\n",
    "    # Content from: \"http://thenextweb.com/apps/2013/03/21/swayy-discover-curate-content/\"\n",
    "\n",
    "title = \"\"\"\n",
    "<< The Title of Article >>\n",
    "\"\"\"\n",
    "\n",
    "#    content = open('G:\\Tool_PGM\\Python\\000Code\\nusbotpaper.txt', encoding = \"ISO-8859-1\", errors='ignore')\n",
    "#    with codecs.open('G:\\Tool_PGM\\Python\\000Code\\nusbotpaper.txt', \"r\", encoding=\"ISO-8859-1\", errors='ignore') as fcontent:\n",
    "#    content = fcontent\n",
    "#    f = open('G:\\Tool_PGM\\Python\\000Code\\nusbotpaper.txt', encoding = \"ISO-8859-1\", errors='ignore')\n",
    "#    content = Rtf15Reader.read(f)\n",
    "#    f.close()\n",
    "\n",
    "content = \"\"\"\n",
    "1 INTRODUCTION\n",
    "It was built based on UAlbertaBot 2013 architecture, which employs a Multi-Agent based design system\n",
    "NUS-Bot originated a high-level strategic reasoning mechanism, consisting Intelligence Preparation of the Battlefield (IPB) and Layered Influence Map (LIM)\n",
    "It is a systematic, continuous process of analyzing the threat and environment in a specific geographic area\n",
    "Applying the IPB process helps the commander selectively apply and maximize his combat power at critical points in time and space on the battlefield via:\n",
    "LIMâ€™s update frequency can vary in order to produce different granularity for different scale of reasoning requirements, to satisfy real-time computation expenditure\n",
    "\n",
    "The dendrogram of the hierarchical clustering shows 2 distant clusters, with the larger of the 2 breaking into another 2 clusters\n",
    "The clustering algorithm was run iteratively from 2 to 10 initial centroids and the resulting Sum (withinSS) plot showed a massive drop in the different from the previous within cluster sum of squared error at the iteration using 4 clusters\n",
    "The first 2 principal components preserved 80% of the information in the data.\n",
    "\n",
    "A possible alternative to the above methodology would be to apply outlier detection techniques such as local outlier factor (LOF) or local density cluster-based outlier factor (LDCOF) to identify and remove such outliers first before commencing hierarchical and the subsequent k-means clustering\n",
    "These games run very long, have low to medium game scores per second, have relatively low winner and loser scores, and low winner/loser scores (0.4 to around 5)? It suggests that the gameplay was largely defensive and focused on construction and resource gathering\n",
    "The large range in winner/loser scores from 0.4 to 32 suggests that the dominant strategy was played against a wide variety of other strategies\n",
    "It suggests that the dominant engagement strategy in this game was that of balanced aggressive builders who manage to progress to mid-game with mid-level units and yet constant engage their opponent's units and buildings which explains the high game scores/second.\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< The Title of Article >>\n",
      "\n",
      "It is a systematic, continuous process of analyzing the threat and environment in a specific geographic area\n",
      "The clustering algorithm was run iteratively from 2 to 10 initial centroids and the resulting Sum (withinSS) plot showed a massive drop in the different from the previous within cluster sum of squared error at the iteration using 4 clusters\n",
      "The large range in winner/loser scores from 0.4 to 32 suggests that the dominant strategy was played against a wide variety of other strategies\n",
      "\n",
      "Original Length 2159\n",
      "Summary Length 521\n",
      "Summary Ratio: 75.8684576193\n"
     ]
    }
   ],
   "source": [
    "    # Create a SummaryTool object\n",
    "st = SummaryTool()\n",
    "\n",
    "    # Build the sentences dictionary\n",
    "sentences_dic = st.get_senteces_ranks(content)\n",
    "\n",
    "    # Build the summary with the sentences dictionary\n",
    "summary = st.get_summary(title, content, sentences_dic)\n",
    "\n",
    "    # print the summary\n",
    "print(summary)\n",
    "\n",
    "    # print(the ratio between the summary length and the original length\n",
    "print(\"\")\n",
    "print(\"Original Length %s\" % (len(title) + len(content)))\n",
    "print(\"Summary Length %s\" % len(summary))\n",
    "print(\"Summary Ratio: %s\" % (100 - (100 * (len(summary) / (len(title) + len(content))))))\n",
    "\n",
    "#   output file locaiotn: G:\\Tool_PGM\\Python\\\n",
    "#     f = open(\"nusbot_summary.txt\",\"w\") \n",
    "#     f.write(\"Original Length %s\" % (len(title) + len(content)))\n",
    "#     f.write(\"\\n\")\n",
    "#     f.write(\"Summary Length %s\" % len(summary))\n",
    "#     f.write(\"\\n\")\n",
    "#     f.write(\"Summary Ratio: %s\" % (100 - (100 * (len(summary) / (len(title) + len(content))))))\n",
    "#     f.write(\"\\n\")\n",
    "#     f.write(\"\\n\")\n",
    "#     f.write(summary)\n",
    "#     f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
