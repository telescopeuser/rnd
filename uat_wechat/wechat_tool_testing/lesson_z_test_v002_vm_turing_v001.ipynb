{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å¦‚ä½•ä½¿ç”¨å’Œå¼€å‘å¾®ä¿¡èŠå¤©æœºå™¨äººçš„ç³»åˆ—æ•™ç¨‹\n",
    "# A workshop to develop & use an intelligent and interactive chat-bot in WeChat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WeChat is a popular social media app, which has more than 800 million monthly active users.\n",
    "\n",
    "<img src='http://www.kudosdata.com/wp-content/uploads/2016/11/cropped-KudosLogo1.png' width=30% style=\"float: right;\">\n",
    "<img src='reference/WeChat_SamGu_QR.png' width=10% style=\"float: right;\">\n",
    "\n",
    "### http://www.KudosData.com\n",
    "\n",
    "by: Sam.Gu@KudosData.com\n",
    "\n",
    "\n",
    "May 2017 ========== Scan the QR code to become trainer's friend in WeChat ========>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç¬¬ä¸‰è¯¾ï¼šè‡ªç„¶è¯­è¨€å¤„ç†\n",
    "### Lesson 3: Natural Language Processing\n",
    "* æ¶ˆæ¯æ–‡å­—è½¬æˆè¯­éŸ³ (Speech synthesis: text to voice)\n",
    "* è¯­éŸ³è½¬æ¢æˆæ¶ˆæ¯æ–‡å­— (Speech recognition: voice to text)\n",
    "* æ¶ˆæ¯æ–‡å­—çš„å¤šè¯­è¨€äº’è¯‘ (Text based language translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flag to indicate the environment to run this program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parm_runtime_env_GCP = True\n",
    "parm_runtime_env_GCP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using Google Cloud Platform's Machine Learning APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the same API console, choose \"Dashboard\" on the left-hand menu and \"Enable API\".\n",
    "\n",
    "Enable the following APIs for your project (search for them) if they are not already enabled:\n",
    "<ol>\n",
    "<li> Google Translate API </li>\n",
    "<li> Google Cloud Vision API </li>\n",
    "<li> Google Natural Language API </li>\n",
    "<li> Google Cloud Speech API </li>\n",
    "</ol>\n",
    "\n",
    "Finally, because we are calling the APIs from Python (clients in many other languages are available), let's install the Python package (it's not installed by default on Datalab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 Google Inc.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
    "# import subprocess\n",
    "# retcode = subprocess.call(['pip', 'install', '-U', 'google-api-python-client'])\n",
    "# retcode = subprocess.call(['pip', 'install', '-U', 'gTTS'])\n",
    "\n",
    "# Below is for GCP only: install audio conversion tool\n",
    "# retcode = subprocess.call(['apt-get', 'update', '-y'])\n",
    "# retcode = subprocess.call(['apt-get', 'install', 'libav-tools', '-y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¯¼å…¥éœ€è¦ç”¨åˆ°çš„ä¸€äº›åŠŸèƒ½ç¨‹åºåº“ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–ˆ\r"
     ]
    }
   ],
   "source": [
    "import io, os, subprocess, sys, re, codecs, time, datetime, requests, itchat\n",
    "from itchat.content import *\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### GCP Machine Learning API Key\n",
    "\n",
    "First, visit <a href=\"http://console.cloud.google.com/apis\">API console</a>, choose \"Credentials\" on the left-hand menu.  Choose \"Create Credentials\" and generate an API key for your application. You should probably restrict it by IP address to prevent abuse, but for now, just  leave that field blank and delete the API key after trying out this demo.\n",
    "\n",
    "Copy-paste your API Key here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here I read in my own API_KEY from a file, which is not shared in Github repository:\n",
    "with io.open('../../../API_KEY.txt') as fp: \n",
    "    for line in fp: APIKEY = line\n",
    "\n",
    "# You need to un-comment below line and replace 'APIKEY' variable with your own GCP API key:\n",
    "# APIKEY=\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below is for Google Speech synthesis: text to voice API\n",
    "from gtts import gTTS\n",
    "\n",
    "# Below is for  Google Speech recognition: voice to text API\n",
    "speech_service = build('speech', 'v1', developerKey=APIKEY)\n",
    "\n",
    "# Below is for Google Language Tranlation API\n",
    "service = build('translate', 'v2', developerKey=APIKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¤šåª’ä½“äºŒè¿›åˆ¶base64ç è½¬æ¢ (Define image pre-processing functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the base64 encoding library.\n",
    "import base64\n",
    "# Pass the image data to an encoding function.\n",
    "def encode_image(image_file):\n",
    "    with io.open(image_file, \"rb\") as image_file:\n",
    "        image_content = image_file.read()\n",
    "# Python 2\n",
    "    if sys.version_info[0] < 3:\n",
    "        return base64.b64encode(image_content)\n",
    "# Python 3\n",
    "    else:\n",
    "        return base64.b64encode(image_content).decode('utf-8')\n",
    "\n",
    "# Pass the audio data to an encoding function.\n",
    "def encode_audio(audio_file):\n",
    "    with io.open(audio_file, 'rb') as audio_file:\n",
    "        audio_content = audio_file.read()\n",
    "# Python 2\n",
    "    if sys.version_info[0] < 3:\n",
    "        return base64.b64encode(audio_content)\n",
    "# Python 3\n",
    "    else:\n",
    "        return base64.b64encode(audio_content).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æœºå™¨æ™ºèƒ½APIæ¥å£æ§åˆ¶å‚æ•° (Define control parameters for API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# API control parameter for Image API:\n",
    "parm_image_maxResults = 10 # max objects or faces to be extracted from image analysis\n",
    "\n",
    "# API control parameter for Language Translation API:\n",
    "parm_translation_origin_language = 'zh' # original language in text: to be overwriten by TEXT_DETECTION\n",
    "parm_translation_target_language = 'zh' # target language for translation: Chinese\n",
    "\n",
    "\n",
    "# API control parameter for æ¶ˆæ¯æ–‡å­—è½¬æˆè¯­éŸ³ (Speech synthesis: text to voice)\n",
    "parm_speech_synthesis_language = 'zh' # speech synthesis API 'text to voice' language\n",
    "# parm_speech_synthesis_language = 'zh-tw' # speech synthesis API 'text to voice' language\n",
    "# parm_speech_synthesis_language = 'zh-yue' # speech synthesis API 'text to voice' language\n",
    "\n",
    "# API control parameter for è¯­éŸ³è½¬æ¢æˆæ¶ˆæ¯æ–‡å­— (Speech recognition: voice to text)\n",
    "# parm_speech_recognition_language = 'en' # speech API 'voice to text' language\n",
    "parm_speech_recognition_language = 'cmn-Hans-CN' # speech API 'voice to text' language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'LABEL_DETECTION'\n",
    "def KudosData_LABEL_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' ç‰©ä½“è¯†åˆ« ]\\n'\n",
    "    # 'LABEL_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        for i in range(len(responses['responses'][0]['labelAnnotations'])):\n",
    "            image_analysis_reply += responses['responses'][0]['labelAnnotations'][i]['description'] \\\n",
    "            + '\\n( confidence ' +  str(responses['responses'][0]['labelAnnotations'][i]['score']) + ' )\\n'\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill æ— ç»“æœ ]\\n'\n",
    "        \n",
    "    return image_analysis_reply\n",
    "  \n",
    "# Running Vision API\n",
    "# 'LANDMARK_DETECTION'\n",
    "def KudosData_LANDMARK_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' åœ°æ ‡è¯†åˆ« ]\\n'\n",
    "    # 'LANDMARK_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        for i in range(len(responses['responses'][0]['landmarkAnnotations'])):\n",
    "            image_analysis_reply += responses['responses'][0]['landmarkAnnotations'][i]['description'] \\\n",
    "            + '\\n( confidence ' +  str(responses['responses'][0]['landmarkAnnotations'][i]['score']) + ' )\\n'\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill æ— ç»“æœ ]\\n'\n",
    "        \n",
    "    return image_analysis_reply\n",
    "\n",
    "# Running Vision API\n",
    "# 'LOGO_DETECTION'\n",
    "def KudosData_LOGO_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' å•†æ ‡è¯†åˆ« ]\\n'\n",
    "    # 'LOGO_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        for i in range(len(responses['responses'][0]['logoAnnotations'])):\n",
    "            image_analysis_reply += responses['responses'][0]['logoAnnotations'][i]['description'] \\\n",
    "            + '\\n( confidence ' +  str(responses['responses'][0]['logoAnnotations'][i]['score']) + ' )\\n'\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill æ— ç»“æœ ]\\n'\n",
    "        \n",
    "    return image_analysis_reply\n",
    "  \n",
    "# Running Vision API\n",
    "# 'TEXT_DETECTION'\n",
    "def KudosData_TEXT_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' æ–‡å­—æå– ]\\n'\n",
    "    # 'TEXT_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        image_analysis_reply += u'----- Start Original Text -----\\n'\n",
    "        image_analysis_reply += u'( Original Language åŸæ–‡: ' + responses['responses'][0]['textAnnotations'][0]['locale'] \\\n",
    "        + ' )\\n'        \n",
    "        image_analysis_reply += responses['responses'][0]['textAnnotations'][0]['description'] + '----- End Original Text -----\\n'\n",
    "\n",
    "        ##############################################################################################################\n",
    "        #                                        translation of detected text                                        #\n",
    "        ##############################################################################################################\n",
    "        parm_translation_origin_language = responses['responses'][0]['textAnnotations'][0]['locale']\n",
    "        # Call translation if parm_translation_origin_language is not parm_translation_target_language\n",
    "        if parm_translation_origin_language != parm_translation_target_language:\n",
    "            inputs=[responses['responses'][0]['textAnnotations'][0]['description']] # TEXT_DETECTION OCR results only\n",
    "            outputs = service.translations().list(source=parm_translation_origin_language, \n",
    "                                                  target=parm_translation_target_language, q=inputs).execute()\n",
    "            image_analysis_reply += u'\\n----- Start Translation -----\\n'\n",
    "            image_analysis_reply += u'( Target Language è¯‘æ–‡: ' + parm_translation_target_language + ' )\\n'\n",
    "            image_analysis_reply += outputs['translations'][0]['translatedText'] + '\\n' + '----- End Translation -----\\n'\n",
    "            print('Compeleted: Translation    API ...')\n",
    "        ##############################################################################################################\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill æ— ç»“æœ ]\\n'\n",
    "        \n",
    "    return image_analysis_reply\n",
    "  \n",
    "# Running Vision API\n",
    "# 'FACE_DETECTION'\n",
    "def KudosData_FACE_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' é¢éƒ¨è¡¨æƒ… ]\\n'\n",
    "    # 'FACE_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        for i in range(len(responses['responses'][0]['faceAnnotations'])):\n",
    "            image_analysis_reply += u'----- No.' + str(i+1) + ' Face -----\\n'\n",
    "            \n",
    "            image_analysis_reply += u'>>> Joy å–œæ‚¦: \\n' \\\n",
    "            + responses['responses'][0]['faceAnnotations'][i][u'joyLikelihood'] + '\\n'\n",
    "            \n",
    "            image_analysis_reply += u'>>> Anger æ„¤æ€’: \\n' \\\n",
    "            + responses['responses'][0]['faceAnnotations'][i][u'angerLikelihood'] + '\\n'\n",
    "            \n",
    "            image_analysis_reply += u'>>> Sorrow æ‚²ä¼¤: \\n' \\\n",
    "            + responses['responses'][0]['faceAnnotations'][i][u'sorrowLikelihood'] + '\\n'\n",
    "            \n",
    "            image_analysis_reply += u'>>> Surprise æƒŠå¥‡: \\n' \\\n",
    "            + responses['responses'][0]['faceAnnotations'][i][u'surpriseLikelihood'] + '\\n'\n",
    "            \n",
    "            image_analysis_reply += u'>>> Headwear å¤´é¥°: \\n' \\\n",
    "            + responses['responses'][0]['faceAnnotations'][i][u'headwearLikelihood'] + '\\n'\n",
    "            \n",
    "            image_analysis_reply += u'>>> Blurred æ¨¡ç³Š: \\n' \\\n",
    "            + responses['responses'][0]['faceAnnotations'][i][u'blurredLikelihood'] + '\\n'\n",
    "            \n",
    "            image_analysis_reply += u'>>> UnderExposed æ¬ æ›å…‰: \\n' \\\n",
    "            + responses['responses'][0]['faceAnnotations'][i][u'underExposedLikelihood'] + '\\n'\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill æ— ç»“æœ ]\\n'\n",
    "            \n",
    "    return image_analysis_reply\n",
    "  \n",
    "# Running Vision API\n",
    "# 'SAFE_SEARCH_DETECTION'\n",
    "def KudosData_SAFE_SEARCH_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' ä¸è‰¯å†…å®¹ ]\\n'\n",
    "    # 'SAFE_SEARCH_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        image_analysis_reply += u'>>> Adult æˆäºº: \\n' + responses['responses'][0]['safeSearchAnnotation'][u'adult'] + '\\n'\n",
    "        image_analysis_reply += u'>>> Violence æš´åŠ›: \\n' + responses['responses'][0]['safeSearchAnnotation'][u'violence'] + '\\n'\n",
    "        image_analysis_reply += u'>>> Spoof æ¬ºéª—: \\n' + responses['responses'][0]['safeSearchAnnotation'][u'spoof'] + '\\n'\n",
    "        image_analysis_reply += u'>>> Medical åŒ»ç–—: \\n' + responses['responses'][0]['safeSearchAnnotation'][u'medical'] + '\\n'\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill æ— ç»“æœ ]\\n'\n",
    "    return image_analysis_reply\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### * æ¶ˆæ¯æ–‡å­—è½¬æˆè¯­éŸ³ (Speech synthesis: text to voice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported Languages  \n",
    "\n",
    "https://pypi.python.org/pypi/gTTS\n",
    "\n",
    "\n",
    "'**af**' : 'Afrikaans'  '**sq**' : 'Albanian'  '**ar**' : 'Arabic'  '**hy**' : 'Armenian'  '**bn**' : 'Bengali'  '**ca**' : 'Catalan'  '**zh**' : 'Chinese'  '**zh-cn**' : 'Chinese (Mandarin/China)'  '**zh-tw**' : 'Chinese (Mandarin/Taiwan)'  '**zh-yue**' : 'Chinese (Cantonese)'  '**hr**' : 'Croatian'  '**cs**' : 'Czech'  '**da**' : 'Danish'  '**nl**' : 'Dutch'  '**en**' : 'English'  '**en-au**' : 'English (Australia)'  '**en-uk**' : 'English (United Kingdom)'  '**en-us**' : 'English (United States)'  '**eo**' : 'Esperanto'  '**fi**' : 'Finnish'  '**fr**' : 'French'  '**de**' : 'German'  '**el**' : 'Greek'  '**hi**' : 'Hindi'  '**hu**' : 'Hungarian'  '**is**' : 'Icelandic'  '**id**' : 'Indonesian'  '**it**' : 'Italian'  '**ja**' : 'Japanese'  '**km**' : 'Khmer (Cambodian)'  '**ko**' : 'Korean'  '**la**' : 'Latin'  '**lv**' : 'Latvian'  '**mk**' : 'Macedonian'  '**no**' : 'Norwegian'  '**pl**' : 'Polish'  '**pt**' : 'Portuguese'  '**ro**' : 'Romanian'  '**ru**' : 'Russian'  '**sr**' : 'Serbian'  '**si**' : 'Sinhala'  '**sk**' : 'Slovak'  '**es**' : 'Spanish'  '**es-es**' : 'Spanish (Spain)'  '**es-us**' : 'Spanish (United States)'  '**sw**' : 'Swahili'  '**sv**' : 'Swedish'  '**ta**' : 'Tamil'  '**th**' : 'Thai'  '**tr**' : 'Turkish'  '**uk**' : 'Ukrainian'  '**vi**' : 'Vietnamese'  '**cy**' : 'Welsh'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running Speech API\n",
    "def KudosData_text_to_voice(text2voice): \n",
    "    # Python 2\n",
    "    if sys.version_info[0] < 3: \n",
    "        tts = gTTS(text=text2voice.encode('utf-8'), lang=parm_speech_synthesis_language, slow=False)\n",
    "    # Python 3\n",
    "    else:\n",
    "        tts = gTTS(text=text2voice, lang=parm_speech_synthesis_language, slow=False)\n",
    "\n",
    "    text2voiceMP3name = 'Voice_For_You.mp3'\n",
    "    tts.save(text2voiceMP3name)\n",
    "    print('Compeleted: Speech synthesis API ( Text -> Voice)')\n",
    "    print(text2voice)\n",
    "    return text2voiceMP3name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### * è¯­éŸ³è½¬æ¢æˆæ¶ˆæ¯æ–‡å­— (Speech recognition: voice to text)\n",
    "\n",
    "The Speech API can work on streaming data, audio content encoded and embedded directly into the POST message, or on a file on Cloud Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported Languages  \n",
    "\n",
    "https://cloud.google.com/speech/docs/languages\n",
    "\n",
    "\n",
    "'**af-ZA**' 'Afrikaans (South Africa)' '**id-ID**' 'Indonesian (Indonesia)' '**ms-MY**' 'Malay (Malaysia)' '**ca-ES**' 'Catalan (Spain)' '**cs-CZ**' 'Czech (Czech Republic)' '**da-DK**' 'Danish (Denmark)' '**de-DE**' 'German (Germany)' '**en-AU**' 'English (Australia)' '**en-CA**' 'English (Canada)' '**en-GB**' 'English (United Kingdom)' '**en-IN**' 'English (India)' '**en-IE**' 'English (Ireland)' '**en-NZ**' 'English (New Zealand)' '**en-PH**' 'English (Philippines)' '**en-ZA**' 'English (South Africa)' '**en-US**' 'English (United States)' '**es-AR**' 'Spanish (Argentina)' '**es-BO**' 'Spanish (Bolivia)' '**es-CL**' 'Spanish (Chile)' '**es-CO**' 'Spanish (Colombia)' '**es-CR**' 'Spanish (Costa Rica)' '**es-EC**' 'Spanish (Ecuador)' '**es-SV**' 'Spanish (El Salvador)' '**es-ES**' 'Spanish (Spain)' '**es-US**' 'Spanish (United States)' '**es-GT**' 'Spanish (Guatemala)' '**es-HN**' 'Spanish (Honduras)' '**es-MX**' 'Spanish (Mexico)' '**es-NI**' 'Spanish (Nicaragua)' '**es-PA**' 'Spanish (Panama)' '**es-PY**' 'Spanish (Paraguay)' '**es-PE**' 'Spanish (Peru)' '**es-PR**' 'Spanish (Puerto Rico)' '**es-DO**' 'Spanish (Dominican Republic)' '**es-UY**' 'Spanish (Uruguay)' '**es-VE**' 'Spanish (Venezuela)' '**eu-ES**' 'Basque (Spain)' '**fil-PH**' 'Filipino (Philippines)' '**fr-CA**' 'French (Canada)' '**fr-FR**' 'French (France)' '**gl-ES**' 'Galician (Spain)' '**hr-HR**' 'Croatian (Croatia)' '**zu-ZA**' 'Zulu (South Africa)' '**is-IS**' 'Icelandic (Iceland)' '**it-IT**' 'Italian (Italy)' '**lt-LT**' 'Lithuanian (Lithuania)' '**hu-HU**' 'Hungarian (Hungary)' '**nl-NL**' 'Dutch (Netherlands)' '**nb-NO**' 'Norwegian BokmÃ¥l (Norway)' '**pl-PL**' 'Polish (Poland)' '**pt-BR**' 'Portuguese (Brazil)' '**pt-PT**' 'Portuguese (Portugal)' '**ro-RO**' 'Romanian (Romania)' '**sk-SK**' 'Slovak (Slovakia)' '**sl-SI**' 'Slovenian (Slovenia)' '**fi-FI**' 'Finnish (Finland)' '**sv-SE**' 'Swedish (Sweden)' '**vi-VN**' 'Vietnamese (Vietnam)' '**tr-TR**' 'Turkish (Turkey)' '**el-GR**' 'Greek (Greece)' '**bg-BG**' 'Bulgarian (Bulgaria)' '**ru-RU**' 'Russian (Russia)' '**sr-RS**' 'Serbian (Serbia)' '**uk-UA**' 'Ukrainian (Ukraine)' '**he-IL**' 'Hebrew (Israel)' '**ar-IL**' 'Arabic (Israel)' '**ar-JO**' 'Arabic (Jordan)' '**ar-AE**' 'Arabic (United Arab Emirates)' '**ar-BH**' 'Arabic (Bahrain)' '**ar-DZ**' 'Arabic (Algeria)' '**ar-SA**' 'Arabic (Saudi Arabia)' '**ar-IQ**' 'Arabic (Iraq)' '**ar-KW**' 'Arabic (Kuwait)' '**ar-MA**' 'Arabic (Morocco)' '**ar-TN**' 'Arabic (Tunisia)' '**ar-OM**' 'Arabic (Oman)' '**ar-PS**' 'Arabic (State of Palestine)' '**ar-QA**' 'Arabic (Qatar)' '**ar-LB**' 'Arabic (Lebanon)' '**ar-EG**' 'Arabic (Egypt)' '**fa-IR**' 'Persian (Iran)' '**hi-IN**' 'Hindi (India)' '**th-TH**' 'Thai (Thailand)' '**ko-KR**' 'Korean (South Korea)' '**cmn-Hant-TW**' 'Chinese, Mandarin (Traditional, Taiwan)' '**yue-Hant-HK**' 'Chinese, Cantonese (Traditional, Hong Kong)' '**ja-JP**' 'Japanese (Japan)' '**cmn-Hans-HK**' 'Chinese, Mandarin (Simplified, Hong Kong)' '**cmn-Hans-CN**' 'Chinese, Mandarin (Simplified, China)' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#    msg.download(msg.fileName)\n",
    "#    print('\\nDownloaded image file name is: %s' % msg['FileName'])\n",
    "\n",
    "#    audio_file_input = msg['FileName']\n",
    "#    audio_type = ['flac', 'wav']\n",
    "\n",
    "# Running Speech API\n",
    "def KudosData_voice_to_text(audio_file_input, audio_type):\n",
    "    audio_file_output = str(audio_file_input) + '.' + str(audio_type)\n",
    "#     print('audio_file_input             : %s' % audio_file_input)\n",
    "    print('Converted  audio file for API: %s' % audio_file_output)\n",
    "    \n",
    "    # convert mp3 file to target GCP audio file:\n",
    "\n",
    "# remove audio_file_output, is exist\n",
    "    retcode = subprocess.call(['rm', audio_file_output])\n",
    "    # print(retcode)\n",
    "    \n",
    "    if parm_runtime_env_GCP: # using Datalab in Google Cloud Platform\n",
    "        # GCP: use avconv to convert audio\n",
    "        retcode = subprocess.call(['avconv', '-i', audio_file_input, '-ac', '1', audio_file_output])\n",
    "    else: # using a Kudos Data Virtual Machine, or local machine\n",
    "        # VM : use ffmpeg to convert audio\n",
    "        retcode = subprocess.call(['ffmpeg', '-i', audio_file_input, '-ac', '1', audio_file_output])\n",
    "    # print(retcode)\n",
    "\n",
    "    # Call GCP Speech API:\n",
    "    # response = speech_service.speech().syncrecognize(\n",
    "    response = speech_service.speech().recognize(\n",
    "        body={\n",
    "            'config': {\n",
    "#                 'encoding': 'LINEAR16',\n",
    "#                 'sampleRateHertz': 16000,\n",
    "                'languageCode': parm_speech_recognition_language\n",
    "            },\n",
    "            'audio': {\n",
    "                'content': encode_audio(audio_file_output) # base64 of converted audio file, for speech recognition\n",
    "                }\n",
    "            }).execute()    \n",
    "    print('Compeleted: Speech recognition API ( Voice -> Text )')\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### * æ¶ˆæ¯æ–‡å­—çš„å¤šè¯­è¨€äº’è¯‘ (Text based language translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported Languages  \n",
    "\n",
    "https://cloud.google.com/translate/docs/languages\n",
    "\n",
    "\n",
    "'**af**' 'Afrikaans' '**sq**' 'Albanian' '**am**' 'Amharic' '**ar**' 'Arabic' '**hy**' 'Armenian' '**az**' 'Azeerbaijani' '**eu**' 'Basque' '**be**' 'Belarusian' '**bn**' 'Bengali' '**bs**' 'Bosnian' '**bg**' 'Bulgarian' '**ca**' 'Catalan' '**ceb** (ISO-639-2)' 'Cebuano' '**ny**' 'Chichewa' '**zh-CN** (BCP-47)' 'Chinese (Simplified)' '**zh-TW** (BCP-47)' 'Chinese (Traditional)' '**co**' 'Corsican' '**hr**' 'Croatian' '**cs**' 'Czech' '**da**' 'Danish' '**nl**' 'Dutch' '**en**' 'English' '**eo**' 'Esperanto' '**et**' 'Estonian' '**tl**' 'Filipino' '**fi**' 'Finnish' '**fr**' 'French' '**fy**' 'Frisian' '**gl**' 'Galician' '**ka**' 'Georgian' '**de**' 'German' '**el**' 'Greek' '**gu**' 'Gujarati' '**ht**' 'Haitian Creole' '**ha**' 'Hausa' '**haw** (ISO-639-2)' 'Hawaiian' '**iw**' 'Hebrew' '**hi**' 'Hindi' '**hmn** (ISO-639-2)' 'Hmong' '**hu**' 'Hungarian' '**is**' 'Icelandic' '**ig**' 'Igbo' '**id**' 'Indonesian' '**ga**' 'Irish' '**it**' 'Italian' '**ja**' 'Japanese' '**jw**' 'Javanese' '**kn**' 'Kannada' '**kk**' 'Kazakh' '**km**' 'Khmer' '**ko**' 'Korean' '**ku**' 'Kurdish' '**ky**' 'Kyrgyz' '**lo**' 'Lao' '**la**' 'Latin' '**lv**' 'Latvian' '**lt**' 'Lithuanian' '**lb**' 'Luxembourgish' '**mk**' 'Macedonian' '**mg**' 'Malagasy' '**ms**' 'Malay' '**ml**' 'Malayalam' '**mt**' 'Maltese' '**mi**' 'Maori' '**mr**' 'Marathi' '**mn**' 'Mongolian' '**my**' 'Burmese' '**ne**' 'Nepali' '**no**' 'Norwegian' '**ps**' 'Pashto' '**fa**' 'Persian' '**pl**' 'Polish' '**pt**' 'Portuguese' '**ma**' 'Punjabi' '**ro**' 'Romanian' '**ru**' 'Russian' '**sm**' 'Samoan' '**gd**' 'Scots Gaelic' '**sr**' 'Serbian' '**st**' 'Sesotho' '**sn**' 'Shona' '**sd**' 'Sindhi' '**si**' 'Sinhala' '**sk**' 'Slovak' '**sl**' 'Slovenian' '**so**' 'Somali' '**es**' 'Spanish' '**su**' 'Sundanese' '**sw**' 'Swahili' '**sv**' 'Swedish' '**tg**' 'Tajik' '**ta**' 'Tamil' '**te**' 'Telugu' '**th**' 'Thai' '**tr**' 'Turkish' '**uk**' 'Ukrainian' '**ur**' 'Urdu' '**uz**' 'Uzbek' '**vi**' 'Vietnamese' '**cy**' 'Welsh' '**xh**' 'Xhosa' '**yi**' 'Yiddish' '**yo**' 'Yoruba' '**zu**' 'Zulu' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KudosData_TEXT_TRANSLATION(text, origin_language_code, target_language_code):\n",
    "    # Call translation if parm_translation_origin_language is not parm_translation_target_language\n",
    "    if origin_language_code != target_language_code:\n",
    "        outputs = service.translations().list(source=origin_language_code, \n",
    "                                              target=target_language_code, q=text).execute()\n",
    "        translated_text = ''\n",
    "        translated_text += u'---- Start Translation ----\\n'\n",
    "        translated_text += u'( Origin Lang åŸæ–‡: ' + origin_language_code + ' )\\n'\n",
    "        translated_text += u'( Target Lang è¯‘æ–‡: ' + target_language_code + ' )\\n'\n",
    "        translated_text += outputs['translations'][0]['translatedText'] + '\\n' + '----- End Translation -----\\n'\n",
    "        print('Compeleted: Translation    API : From Language \\'%s\\' to \\'%s\\'' \n",
    "              % (origin_language_code, target_language_code))\n",
    "    else:\n",
    "        translated_text = text\n",
    "        \n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç”¨å¾®ä¿¡Appæ‰«QRç å›¾ç‰‡æ¥è‡ªåŠ¨ç™»å½•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itchat.auto_login(hotReload=True) # hotReload=True: é€€å‡ºç¨‹åºåæš‚å­˜ç™»é™†çŠ¶æ€ã€‚å³ä½¿ç¨‹åºå…³é—­ï¼Œä¸€å®šæ—¶é—´å†…é‡æ–°å¼€å¯ä¹Ÿå¯ä»¥ä¸ç”¨é‡æ–°æ‰«ç ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtain my own Nick Name\n",
    "MySelf = itchat.search_friends()\n",
    "NickName4RegEx = '@' + MySelf['NickName'] + '\\s*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@itchat.msg_register([PICTURE], isGroupChat=True)\n",
    "@itchat.msg_register([PICTURE])\n",
    "def download_files(msg):\n",
    "    parm_translation_origin_language = 'zh' # will be overwriten by TEXT_DETECTION\n",
    "    msg.download(msg.fileName)\n",
    "    print('\\nDownloaded image file name is: %s' % msg['FileName'])\n",
    "    image_base64 = encode_image(msg['FileName'])\n",
    "    \n",
    "    ##############################################################################################################\n",
    "    #                                          call image analysis APIs                                          #\n",
    "    ##############################################################################################################\n",
    "    \n",
    "    image_analysis_reply = u'[ Image Analysis å›¾åƒè¯†åˆ«ç»“æœ ]\\n'\n",
    "\n",
    "    # 1. LABEL_DETECTION:\n",
    "    image_analysis_reply += KudosData_LABEL_DETECTION(image_base64, 'LABEL_DETECTION', parm_image_maxResults)\n",
    "    # 2. LANDMARK_DETECTION:\n",
    "    image_analysis_reply += KudosData_LANDMARK_DETECTION(image_base64, 'LANDMARK_DETECTION', parm_image_maxResults)\n",
    "    # 3. LOGO_DETECTION:\n",
    "    image_analysis_reply += KudosData_LOGO_DETECTION(image_base64, 'LOGO_DETECTION', parm_image_maxResults)\n",
    "    # 4. TEXT_DETECTION:\n",
    "    image_analysis_reply += KudosData_TEXT_DETECTION(image_base64, 'TEXT_DETECTION', parm_image_maxResults)\n",
    "    # 5. FACE_DETECTION:\n",
    "    image_analysis_reply += KudosData_FACE_DETECTION(image_base64, 'FACE_DETECTION', parm_image_maxResults)\n",
    "    # 6. SAFE_SEARCH_DETECTION:\n",
    "    image_analysis_reply += KudosData_SAFE_SEARCH_DETECTION(image_base64, 'SAFE_SEARCH_DETECTION', parm_image_maxResults)\n",
    "\n",
    "    print('Compeleted: Image Analysis API ...')\n",
    "    \n",
    "    return image_analysis_reply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KEY = '71f28bf79c820df10d39b4074345ef8c'\n",
    "\n",
    "'''\n",
    "8edce3ce905a4c1dbb965e6b35c3834d\n",
    "eb720a8970964f3f855d863d24406576\n",
    "1107d5601866433dba9599fac1bc0083\n",
    "71f28bf79c820df10d39b4074345ef8c\n",
    "'''\n",
    "\n",
    "def get_response(msg):\n",
    "    print('... Turing Reply ...')\n",
    "    # è¿™é‡Œæˆ‘ä»¬å°±åƒåœ¨â€œ3. å®ç°æœ€ç®€å•çš„ä¸å›¾çµæœºå™¨äººçš„äº¤äº’â€ä¸­åšçš„ä¸€æ ·\n",
    "    # æ„é€ äº†è¦å‘é€ç»™æœåŠ¡å™¨çš„æ•°æ®\n",
    "    apiUrl = 'http://www.tuling123.com/openapi/api'\n",
    "    data = {\n",
    "        'key'    : KEY,\n",
    "        'info'   : msg,\n",
    "        'userid' : 'wechat-robot',\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(apiUrl, data=data).json()\n",
    "        # å­—å…¸çš„getæ–¹æ³•åœ¨å­—å…¸æ²¡æœ‰'text'å€¼çš„æ—¶å€™ä¼šè¿”å›Noneè€Œä¸ä¼šæŠ›å‡ºå¼‚å¸¸\n",
    "        return r.get('text')\n",
    "    # ä¸ºäº†é˜²æ­¢æœåŠ¡å™¨æ²¡æœ‰æ­£å¸¸å“åº”å¯¼è‡´ç¨‹åºå¼‚å¸¸é€€å‡ºï¼Œè¿™é‡Œç”¨try-exceptæ•è·äº†å¼‚å¸¸\n",
    "    # å¦‚æœæœåŠ¡å™¨æ²¡èƒ½æ­£å¸¸äº¤äº’ï¼ˆè¿”å›éjsonæˆ–æ— æ³•è¿æ¥ï¼‰ï¼Œé‚£ä¹ˆå°±ä¼šè¿›å…¥ä¸‹é¢çš„return\n",
    "    except:\n",
    "        print('!!! Turing Machine problem !!!')\n",
    "        # å°†ä¼šè¿”å›ä¸€ä¸ªNone\n",
    "        return\n",
    "\n",
    "\n",
    "@itchat.msg_register([TEXT, MAP, CARD, NOTE, SHARING])\n",
    "def text_reply(msg):\n",
    "    print()\n",
    "    # ä¸ºäº†ä¿è¯åœ¨å›¾çµKeyå‡ºç°é—®é¢˜çš„æ—¶å€™ä»æ—§å¯ä»¥å›å¤ï¼Œè¿™é‡Œè®¾ç½®ä¸€ä¸ªé»˜è®¤å›å¤\n",
    "    defaultReply = 'I received: ' + msg['Text']\n",
    "    # å¦‚æœå›¾çµKeyå‡ºç°é—®é¢˜ï¼Œé‚£ä¹ˆreplyå°†ä¼šæ˜¯None\n",
    "    reply = get_response(msg['Text'])\n",
    "    \n",
    "    if (reply != ''):\n",
    "        print(reply)\n",
    "#         itchat.send(u'@%s\\u2005%s' % (msg['ActualNickName'], reply), msg['FromUserName'])\n",
    "        itchat.send(u'%s' % reply, msg['FromUserName'])\n",
    "######################################################################################\n",
    "#             text to voice:    \n",
    "#=====================================================================================\n",
    "#         text2voiceMP3name = KudosData_text_to_voice(reply)\n",
    "#         itchat.send('@%s@%s' % ('fil', text2voiceMP3name), msg['FromUserName'])\n",
    "######################################################################################\n",
    "    else:\n",
    "        print(defaultReply)\n",
    "        itchat.send(u'%s' % defaultReply, msg['FromUserName'])\n",
    "    \n",
    "    # a or bçš„æ„æ€æ˜¯ï¼Œå¦‚æœaæœ‰å†…å®¹ï¼Œé‚£ä¹ˆè¿”å›aï¼Œå¦åˆ™è¿”å›b\n",
    "    # æœ‰å†…å®¹ä¸€èˆ¬å°±æ˜¯æŒ‡éç©ºæˆ–è€…éNoneï¼Œä½ å¯ä»¥ç”¨`if a: print('True')`æ¥æµ‹è¯•\n",
    "    # return reply or defaultReply\n",
    "\n",
    "\n",
    "@itchat.msg_register([ATTACHMENT, VIDEO])\n",
    "def download_files(msg):\n",
    "    msg['Text'](msg['FileName'])\n",
    "    return '@%s@%s' % ({'Picture': 'img', 'Video': 'vid'}.get(msg['Type'], 'fil'), msg['FileName'])\n",
    "\n",
    "\n",
    "# 2. è¯­éŸ³è½¬æ¢æˆæ¶ˆæ¯æ–‡å­— (Speech recognition: voice to text)\n",
    "# Then call turing API\n",
    "@itchat.msg_register([RECORDING], isGroupChat=True)\n",
    "# @itchat.msg_register([RECORDING])\n",
    "def download_files(msg):\n",
    "    print()\n",
    "    parm_translation_origin_language = 'zh'\n",
    "    msg.download(msg.fileName)\n",
    "    print('\\nDownloaded audio file name is: %s' % msg['FileName'])\n",
    "    ##############################################################################################################\n",
    "    #                                          call audio analysis APIs                                          #\n",
    "    ##############################################################################################################\n",
    "    response = KudosData_voice_to_text(msg['FileName'], 'flac')\n",
    "    if response != {}:\n",
    "        # ä¸ºäº†ä¿è¯åœ¨å›¾çµKeyå‡ºç°é—®é¢˜çš„æ—¶å€™ä»æ—§å¯ä»¥å›å¤ï¼Œè¿™é‡Œè®¾ç½®ä¸€ä¸ªé»˜è®¤å›å¤\n",
    "        defaultReply = 'I received: ' + response['results'][0]['alternatives'][0]['transcript']\n",
    "        print(defaultReply)\n",
    "        # å¦‚æœå›¾çµKeyå‡ºç°é—®é¢˜ï¼Œé‚£ä¹ˆreplyå°†ä¼šæ˜¯None\n",
    "        reply = get_response(response['results'][0]['alternatives'][0]['transcript'])\n",
    "    else:\n",
    "        # Speech recognition has no result:\n",
    "        reply = (u'å®åœ¨å¯¹ä¸èµ·ï¼Œæˆ‘æ²¡å¬æ¸…æ‚¨è¯´çš„ï¼Œè¯·æ‚¨é‡å¤ä¸€éã€‚')\n",
    "\n",
    "    if (reply != ''):\n",
    "        print(u'@%s\\u2005%s' % (msg['ActualNickName'], reply))\n",
    "        itchat.send(u'@%s\\u2005%s' % (msg['ActualNickName'], reply), msg['FromUserName'])\n",
    "######################################################################################\n",
    "#             text to voice:    \n",
    "#=====================================================================================\n",
    "#         text2voiceMP3name = KudosData_text_to_voice(reply)\n",
    "#         itchat.send('@%s@%s' % ('fil', text2voiceMP3name), msg['FromUserName'])\n",
    "######################################################################################\n",
    "    else:\n",
    "        print(u'@%s\\u2005%s' % (msg['ActualNickName'], defaultReply))\n",
    "        itchat.send(u'@%s\\u2005%s' % (msg['ActualNickName'], defaultReply), msg['FromUserName'])\n",
    "\n",
    "\n",
    "@itchat.msg_register([RECORDING])\n",
    "def download_files(msg):\n",
    "    print()\n",
    "    parm_translation_origin_language = 'zh'\n",
    "    msg.download(msg.fileName)\n",
    "    print('\\nDownloaded audio file name is: %s' % msg['FileName'])\n",
    "    ##############################################################################################################\n",
    "    #                                          call audio analysis APIs                                          #\n",
    "    ##############################################################################################################\n",
    "    response = KudosData_voice_to_text(msg['FileName'], 'flac')\n",
    "    if response != {}:\n",
    "        # ä¸ºäº†ä¿è¯åœ¨å›¾çµKeyå‡ºç°é—®é¢˜çš„æ—¶å€™ä»æ—§å¯ä»¥å›å¤ï¼Œè¿™é‡Œè®¾ç½®ä¸€ä¸ªé»˜è®¤å›å¤\n",
    "        defaultReply = 'I received: ' + response['results'][0]['alternatives'][0]['transcript']\n",
    "        print(defaultReply)\n",
    "        # å¦‚æœå›¾çµKeyå‡ºç°é—®é¢˜ï¼Œé‚£ä¹ˆreplyå°†ä¼šæ˜¯None\n",
    "        reply = get_response(response['results'][0]['alternatives'][0]['transcript'])\n",
    "    else:\n",
    "        # Speech recognition has no result:\n",
    "        reply = (u'å®åœ¨å¯¹ä¸èµ·ï¼Œæˆ‘æ²¡å¬æ¸…æ‚¨è¯´çš„ï¼Œè¯·æ‚¨é‡å¤ä¸€éã€‚')\n",
    "\n",
    "    if (reply != ''):\n",
    "        print(reply)\n",
    "#         itchat.send(u'@%s\\u2005%s' % (msg['ActualNickName'], reply), msg['FromUserName'])\n",
    "        itchat.send(u'%s' % reply, msg['FromUserName'])\n",
    "######################################################################################\n",
    "#             text to voice:    \n",
    "#=====================================================================================\n",
    "#         text2voiceMP3name = KudosData_text_to_voice(reply)\n",
    "#         itchat.send('@%s@%s' % ('fil', text2voiceMP3name), msg['FromUserName'])\n",
    "######################################################################################\n",
    "    else:\n",
    "        print(defaultReply)\n",
    "        itchat.send(u'%s' % defaultReply, msg['FromUserName'])\n",
    "\n",
    "\n",
    "# @itchat.msg_register(TEXT, MAP, CARD, NOTE, SHARING, isGroupChat=True) # Group must be saved by current user/chat-bot\n",
    "@itchat.msg_register(TEXT, isGroupChat=True) # Group must be saved by current user/chat-bot\n",
    "def text_reply(msg):\n",
    "    if msg['isAt']:\n",
    "        print()\n",
    "        # ä¸ºäº†ä¿è¯åœ¨å›¾çµKeyå‡ºç°é—®é¢˜çš„æ—¶å€™ä»æ—§å¯ä»¥å›å¤ï¼Œè¿™é‡Œè®¾ç½®ä¸€ä¸ªé»˜è®¤å›å¤\n",
    "        defaultReply = 'I received: ' + msg['Text']\n",
    "        # å¦‚æœå›¾çµKeyå‡ºç°é—®é¢˜ï¼Œé‚£ä¹ˆreplyå°†ä¼šæ˜¯None\n",
    "        reply = get_response(msg['Text'])        \n",
    "        # a or bçš„æ„æ€æ˜¯ï¼Œå¦‚æœaæœ‰å†…å®¹ï¼Œé‚£ä¹ˆè¿”å›aï¼Œå¦åˆ™è¿”å›b\n",
    "        # æœ‰å†…å®¹ä¸€èˆ¬å°±æ˜¯æŒ‡éç©ºæˆ–è€…éNoneï¼Œä½ å¯ä»¥ç”¨`if a: print('True')`æ¥æµ‹è¯•\n",
    "        # return reply or defaultReply\n",
    "        if (reply != ''):\n",
    "            print(u'@%s\\u2005%s' % (msg['ActualNickName'], reply))\n",
    "            itchat.send(u'@%s\\u2005%s' % (msg['ActualNickName'], reply), msg['FromUserName'])\n",
    "######################################################################################\n",
    "#             text to voice:    \n",
    "#=====================================================================================\n",
    "#             text2voiceMP3name = KudosData_text_to_voice(reply)\n",
    "#             itchat.send('@%s@%s' % ('fil', text2voiceMP3name), msg['FromUserName'])\n",
    "######################################################################################\n",
    "        else:\n",
    "#             print(u'@%s\\u2005%s' % (msg['ActualNickName'], defaultReply))\n",
    "            itchat.send(u'@%s\\u2005%s' % (msg['ActualNickName'], defaultReply), msg['FromUserName'])\n",
    "\n",
    "    \n",
    "@itchat.msg_register(FRIENDS)\n",
    "def add_friend(msg):\n",
    "    itchat.add_friend(**msg['Text']) # è¯¥æ“ä½œä¼šè‡ªåŠ¨å°†æ–°å¥½å‹çš„æ¶ˆæ¯å½•å…¥ï¼Œä¸éœ€è¦é‡è½½é€šè®¯å½•\n",
    "    itchat.send_msg('Nice to meet you!', msg['RecommendInfo']['UserName'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start auto replying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Downloaded audio file name is: 170516-223155.mp3\n",
      "Converted  audio file for API: 170516-223155.mp3.flac\n",
      "Compeleted: Speech recognition API ( Voice -> Text )\n",
      "I received: ä½ æ˜¯è°\n",
      "... Turing Reply ...\n",
      "æˆ‘æ˜¯æ£’æ£’å“’å°å†°\n",
      "\n",
      "\n",
      "Downloaded audio file name is: 170516-223208.mp3\n",
      "Converted  audio file for API: 170516-223208.mp3.flac\n",
      "Compeleted: Speech recognition API ( Voice -> Text )\n",
      "I received: æ­¦å¿—çº¢\n",
      "... Turing Reply ...\n",
      "@Sam GUâ€…æ­¦å¿—çº¢ï¼Œå¸¸ç§°è‡ªå·±çš„çŒ«å«äººçŒ«å¤§çœ¼ã€‚ä»–çš„å¾®åšä¸­æ›¾æåˆ°â€œä¸ºä»€ä¹ˆå«å®ƒäººçŒ«ï¼Œå› ä¸ºå®ƒå¸¸åƒäººä¸€æ ·åç€ã€‚â€\n",
      "\n",
      "... Turing Reply ...\n",
      "@Sam GUâ€…æ‚„æ‚„çš„å‘Šè¯‰ä½ ã€€æˆ‘æœ‰ç‚¹å–œæ¬¢ä¸Šä½ äº†å“‡\n",
      "\n",
      "... Turing Reply ...\n",
      "ä½ çŒœï¼vï¼\n",
      "\n",
      "... Turing Reply ...\n",
      "@é…·è±†æœºå™¨äººâ€…ä½ ä»€ä¹ˆæƒ…å†µï¼Ÿä¸ºä»€ä¹ˆè¿™æ ·è¯´å‘€\n",
      "\n",
      "... Turing Reply ...\n",
      "@é…·è±†æœºå™¨äººâ€…å¥½å§ã€€ä½ èµ¢äº†å•¦\n",
      "\n",
      "... Turing Reply ...\n",
      "@jiayiğŸƒğŸœğŸ¶ğŸ¶â€…è¶Šæ¥è¶Šå–œæ¬¢ä½ äº†å‘¢\n",
      "\n",
      "... Turing Reply ...\n",
      "@jiayiğŸƒğŸœğŸ¶ğŸ¶â€…å°å†°ä¹Ÿä¸çŸ¥é“æ˜¯ä»€ä¹ˆè€¶\n",
      "\n",
      "... Turing Reply ...\n",
      "@jiayiğŸƒğŸœğŸ¶ğŸ¶â€…ä½ é™¤äº†é™ªèŠè¿˜é™ªä»€ä¹ˆ\n",
      "\n",
      "... Turing Reply ...\n",
      "@é…·è±†æ•°æ®ç§‘å­¦å®¶ é¡¾ç» Samâ€…å‘µå‘µã€€çŸ¥æˆ‘è€…è°“æˆ‘å¿ƒå¿§ï¼Œä¸çŸ¥æˆ‘è€…è°“æˆ‘ä½•æ±‚å‘¢\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 386, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 382, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/usr/lib64/python3.5/http/client.py\", line 1174, in getresponse\n",
      "    response.begin()\n",
      "  File \"/usr/lib64/python3.5/http/client.py\", line 282, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/usr/lib64/python3.5/http/client.py\", line 251, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/requests/adapters.py\", line 438, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 649, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/requests/packages/urllib3/util/retry.py\", line 357, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/requests/packages/urllib3/packages/six.py\", line 685, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 386, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 382, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/usr/lib64/python3.5/http/client.py\", line 1174, in getresponse\n",
      "    response.begin()\n",
      "  File \"/usr/lib64/python3.5/http/client.py\", line 282, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/usr/lib64/python3.5/http/client.py\", line 251, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "requests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/itchat-1.3.4-py3.5.egg/itchat/components/login.py\", line 238, in maintain_loop\n",
      "    msgList, contactList = self.get_msg()\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/itchat-1.3.4-py3.5.egg/itchat/components/login.py\", line 304, in get_msg\n",
      "    r = self.s.post(url, data=json.dumps(data), headers=headers)\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/requests/sessions.py\", line 565, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/requests/sessions.py\", line 518, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/requests/sessions.py\", line 639, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/requests/adapters.py\", line 488, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... Turing Reply ...\n",
      "@Dies.Iraeâ€…ä½ è§‰å¾—å¥½ï¼Œé‚£å°±æ˜¯æœ€å¥½çš„å“‡\n",
      "\n",
      "... Turing Reply ...\n",
      "@Sam GUâ€…å“¦å“¦ï¼Œæˆ‘çŸ¥é“äº†ï¼Œæˆ‘ä»¬èŠç‚¹åˆ«çš„å§\n",
      "\n",
      "Downloaded image file name is: 170516-223945.gif\n",
      "Compeleted: Image Analysis API ...\n",
      "\n",
      "\n",
      "Downloaded audio file name is: 170516-224409.mp3\n",
      "Converted  audio file for API: 170516-224409.mp3.flac\n",
      "Compeleted: Speech recognition API ( Voice -> Text )\n",
      "I received: å…³äºæœºå™¨äººçš„ä¸–ç•Œ\n",
      "... Turing Reply ...\n",
      "@Sam GUâ€…ä¸–ç•Œæœºå™¨äººè¶³çƒæ¯”èµ›ä¸­å›½å–å¾—ç¬¬ä¸€ã€‚ å¯Œå£«åº·å†³å®šç”¨æœºå™¨äººæ›¿æ¢å¤§é‡å·¥äººã€‚\n",
      "\n",
      "Downloaded image file name is: 170516-224439.png\n",
      "Compeleted: Translation    API ...\n",
      "Compeleted: Image Analysis API ...\n",
      "\n",
      "... Turing Reply ...\n",
      "@ç™½é»‘â€…è¯´çš„ä¹Ÿæ˜¯ã€€å‘€å˜»å˜»\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/itchat-1.3.4-py3.5.egg/itchat/components/register.py\", line 60, in configured_reply\n",
      "    r = replyFn(msg)\n",
      "  File \"<ipython-input-15-ecae4101a734>\", line 77, in download_files\n",
      "    response = KudosData_voice_to_text(msg['FileName'], 'flac')\n",
      "  File \"<ipython-input-10-bbe6cc53dd2a>\", line 37, in KudosData_voice_to_text\n",
      "    'content': encode_audio(audio_file_output) # base64 of converted audio file, for speech recognition\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/oauth2client/_helpers.py\", line 133, in positional_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/googleapiclient/http.py\", line 835, in execute\n",
      "    method=str(self.method), body=self.body, headers=self.headers)\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/googleapiclient/http.py\", line 175, in _retry_request\n",
      "    raise exception\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/googleapiclient/http.py\", line 162, in _retry_request\n",
      "    resp, content = http.request(uri, method, *args, **kwargs)\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/httplib2/__init__.py\", line 1322, in request\n",
      "    (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey)\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/httplib2/__init__.py\", line 1072, in _request\n",
      "    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n",
      "  File \"/home/user/env_py3/lib/python3.5/site-packages/httplib2/__init__.py\", line 996, in _conn_request\n",
      "    conn.request(method, request_uri, body, headers)\n",
      "  File \"/usr/lib64/python3.5/http/client.py\", line 1083, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/lib64/python3.5/http/client.py\", line 1128, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/lib64/python3.5/http/client.py\", line 1079, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/lib64/python3.5/http/client.py\", line 913, in _send_output\n",
      "    self.send(message_body)\n",
      "  File \"/usr/lib64/python3.5/http/client.py\", line 885, in send\n",
      "    self.sock.sendall(data)\n",
      "  File \"/usr/lib64/python3.5/ssl.py\", line 886, in sendall\n",
      "    v = self.send(data[count:])\n",
      "  File \"/usr/lib64/python3.5/ssl.py\", line 856, in send\n",
      "    return self._sslobj.write(data)\n",
      "  File \"/usr/lib64/python3.5/ssl.py\", line 581, in write\n",
      "    return self._sslobj.write(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloaded audio file name is: 170516-230038.mp3\n",
      "Converted  audio file for API: 170516-230038.mp3.flac\n",
      "\n",
      "\n",
      "Downloaded audio file name is: 170516-230106.mp3\n",
      "Converted  audio file for API: 170516-230106.mp3.flac\n",
      "Compeleted: Speech recognition API ( Voice -> Text )\n",
      "I received: å–‚å–‚æ‰“ç”µè¯\n",
      "... Turing Reply ...\n",
      "@Sam GUâ€…æˆ‘ç°åœ¨è¿˜æ²¡å­¦ä¼šæ‰“ç”µè¯å‘¢\n",
      "\n",
      "\n",
      "Downloaded audio file name is: 170516-230126.mp3\n",
      "Converted  audio file for API: 170516-230126.mp3.flac\n",
      "Compeleted: Speech recognition API ( Voice -> Text )\n",
      "@Sam GUâ€…å®åœ¨å¯¹ä¸èµ·ï¼Œæˆ‘æ²¡å¬æ¸…æ‚¨è¯´çš„ï¼Œè¯·æ‚¨é‡å¤ä¸€éã€‚\n",
      "\n",
      "... Turing Reply ...\n",
      "@Sam GUâ€…è¯´çš„éå¸¸æœ‰é“ç†ã€€é¼“æŒè€¶ï½\n"
     ]
    }
   ],
   "source": [
    "itchat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interupt kernel, then logout\n",
    "itchat.logout() # å®‰å…¨é€€å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ­å–œæ‚¨ï¼å·²ç»å®Œæˆäº†ï¼š\n",
    "### ç¬¬ä¸‰è¯¾ï¼šè‡ªç„¶è¯­è¨€å¤„ç†\n",
    "### Lesson 3: Natural Language Processing\n",
    "* æ¶ˆæ¯æ–‡å­—è½¬æˆè¯­éŸ³ (Speech synthesis: text to voice)\n",
    "* è¯­éŸ³è½¬æ¢æˆæ¶ˆæ¯æ–‡å­— (Speech recognition: voice to text)\n",
    "* æ¶ˆæ¯æ–‡å­—çš„å¤šè¯­è¨€äº’è¯‘ (Text based language translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¸‹ä¸€è¯¾æ˜¯:\n",
    "### ç¬¬ä¸‰è¯¾ï¼šè‡ªç„¶è¯­è¨€å¤„ç†\n",
    "### Lesson 3: Natural Language Processing\n",
    "* æ¶ˆæ¯æ–‡å­—è½¬æˆè¯­éŸ³ (Speech synthesis: text to voice)\n",
    "* è¯­éŸ³è½¬æ¢æˆæ¶ˆæ¯æ–‡å­— (Speech recognition: voice to text)\n",
    "* æ¶ˆæ¯æ–‡å­—çš„å¤šè¯­è¨€äº’è¯‘ (Text based language translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://www.kudosdata.com/wp-content/uploads/2016/11/cropped-KudosLogo1.png' width=30% style=\"float: right;\">\n",
    "<img src='reference/WeChat_SamGu_QR.png' width=10% style=\"float: left;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# 1. æ¶ˆæ¯æ–‡å­—è½¬æˆè¯­éŸ³ (Speech synthesis: text to voice)\n",
    "\n",
    "# åœ¨ç¾¤é‡Œï¼Œå¦‚æœæ”¶åˆ° @ è‡ªå·±çš„æ–‡å­—ä¿¡æ¯ï¼Œä¼šè‡ªåŠ¨å°†æ–‡å­—è½¬æ¢æˆè¯­éŸ³ï¼Œå†ä»¥ mp3 æ–‡ä»¶æ–¹å¼å‘é€å›å¤ï¼š\n",
    "@itchat.msg_register(TEXT, isGroupChat=True)\n",
    "def text_to_voice_reply(msg):\n",
    "    if msg['isAt']:\n",
    "        # Remove my own Nick Name from message:\n",
    "        text2voice = re.sub(NickName4RegEx, '', msg['Content'])\n",
    "        text2voiceMP3name = KudosData_text_to_voice(text2voice)\n",
    "        itchat.send('@%s@%s' % ('fil', text2voiceMP3name), msg['FromUserName'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. è¯­éŸ³è½¬æ¢æˆæ¶ˆæ¯æ–‡å­— (Speech recognition: voice to text)\n",
    "\n",
    "@itchat.msg_register([RECORDING], isGroupChat=True)\n",
    "@itchat.msg_register([RECORDING])\n",
    "def download_files(msg):\n",
    "    parm_translation_origin_language = 'zh' # will be overwriten by TEXT_DETECTION\n",
    "    msg.download(msg.fileName)\n",
    "    print('\\nDownloaded audio file name is: %s' % msg['FileName'])\n",
    "    \n",
    "    ##############################################################################################################\n",
    "    #                                          call audio analysis APIs                                          #\n",
    "    ##############################################################################################################\n",
    "    \n",
    "    audio_analysis_reply = u'[ Audio Analysis éŸ³é¢‘å¤„ç†ç»“æœ ]\\n'\n",
    "\n",
    "    # Voice to Text:\n",
    "    audio_analysis_reply += u'\\n[ Voice -> Text è¯­éŸ³è¯†åˆ« ]\\n'\n",
    "    response = KudosData_voice_to_text(msg['FileName'], 'flac')\n",
    "#     response = KudosData_voice_to_text(msg['FileName'], 'wav')\n",
    "    if response != {}:\n",
    "        print (response['results'][0]['alternatives'][0]['transcript'])\n",
    "        print ('( confidence %f )' % response['results'][0]['alternatives'][0]['confidence'])\n",
    "        audio_analysis_reply += response['results'][0]['alternatives'][0]['transcript'] + '\\n'\n",
    "        audio_analysis_reply += '( confidence ' + str(response['results'][0]['alternatives'][0]['confidence']) + ' )\\n'\n",
    "        # Translate recognised text to another language:\n",
    "        parm_translation_origin_language = 'zh'\n",
    "        parm_translation_target_language = 'en'\n",
    "        translated_text_reply = KudosData_TEXT_TRANSLATION(response['results'][0]['alternatives'][0]['transcript'], \n",
    "                                                           parm_translation_origin_language, parm_translation_target_language)\n",
    "        print(translated_text_reply)\n",
    "        audio_analysis_reply += translated_text_reply\n",
    "    \n",
    "    return audio_analysis_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# 3. æ¶ˆæ¯æ–‡å­—çš„å¤šè¯­è¨€äº’è¯‘ (Text based language translation)\n",
    "\n",
    "# åœ¨ç¾¤é‡Œï¼Œå¦‚æœæ”¶åˆ° @ è‡ªå·±çš„æ–‡å­—ä¿¡æ¯ï¼Œä¼šè‡ªåŠ¨è¿›è¡Œæ–‡å­—ç¿»è¯‘ï¼Œå†å‘é€å›å¤ï¼š\n",
    "@itchat.msg_register(TEXT, isGroupChat=True)\n",
    "def text_to_translation_reply(msg):\n",
    "    if msg['isAt']:\n",
    "        text4translation = re.sub(NickName4RegEx, '', msg['Content'])\n",
    "        parm_translation_origin_language = 'zh'\n",
    "        parm_translation_target_language = 'en'\n",
    "        translated_text_reply = KudosData_TEXT_TRANSLATION(text4translation, \n",
    "                                                           parm_translation_origin_language, parm_translation_target_language)\n",
    "        print(translated_text_reply)\n",
    "        return translated_text_reply\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined: \n",
    "* æ¶ˆæ¯æ–‡å­—è½¬æˆè¯­éŸ³ (Speech synthesis: text to voice)\n",
    "* æ¶ˆæ¯æ–‡å­—çš„å¤šè¯­è¨€äº’è¯‘ (Text based language translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@itchat.msg_register(TEXT, isGroupChat=True)\n",
    "def text_reply(msg):\n",
    "    if msg['isAt']:\n",
    "        # 1. æ¶ˆæ¯æ–‡å­—è½¬æˆè¯­éŸ³ (Speech synthesis: text to voice)\n",
    "        text2voice = re.sub(NickName4RegEx, '', msg['Content']) # Remove my own Nick Name from message\n",
    "        text2voiceMP3name = KudosData_text_to_voice(text2voice)\n",
    "        itchat.send('@%s@%s' % ('fil', text2voiceMP3name), msg['FromUserName'])\n",
    "        # 3. æ¶ˆæ¯æ–‡å­—çš„å¤šè¯­è¨€äº’è¯‘ (Text based language translation)\n",
    "        text4translation = re.sub(NickName4RegEx, '', msg['Content'])\n",
    "        parm_translation_origin_language = 'zh'\n",
    "        parm_translation_target_language = 'en'\n",
    "        translated_text_reply = KudosData_TEXT_TRANSLATION(text4translation, \n",
    "                                                           parm_translation_origin_language, parm_translation_target_language)\n",
    "        print(translated_text_reply)\n",
    "        return translated_text_reply"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
