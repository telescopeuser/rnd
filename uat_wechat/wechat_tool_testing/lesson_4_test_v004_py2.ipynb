{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何使用和开发微信聊天机器人的系列教程\n",
    "# A workshop to develop & use an intelligent and interactive chat-bot in WeChat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WeChat is a popular social media app, which has more than 800 million monthly active users.\n",
    "\n",
    "<img src='http://www.kudosdata.com/wp-content/uploads/2016/11/cropped-KudosLogo1.png' width=30% style=\"float: right;\">\n",
    "<img src='reference/WeChat_SamGu_QR.png' width=10% style=\"float: right;\">\n",
    "\n",
    "### http://www.KudosData.com\n",
    "\n",
    "by: Sam.Gu@KudosData.com\n",
    "\n",
    "\n",
    "May 2017 ========== Scan the QR code to become trainer's friend in WeChat ========>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四课：自然语言处理：语义和情感分析\n",
    "### Lesson 4: Natural Language Processing 2\n",
    "* 消息文字中名称实体的识别 (Name-Entity detection)\n",
    "* 消息文字中语句的情感分析 (Sentiment analysis, Sentence level)\n",
    "* 整篇消息文字的情感分析 (Sentiment analysis, Document level)\n",
    "* 语句的语法分析 (Syntax / Grammer analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flag to indicate the environment to run this program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parm_runtime_env_GCP = True\n",
    "parm_runtime_env_GCP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using Google Cloud Platform's Machine Learning APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the same API console, choose \"Dashboard\" on the left-hand menu and \"Enable API\".\n",
    "\n",
    "Enable the following APIs for your project (search for them) if they are not already enabled:\n",
    "<ol>\n",
    "<li> Google Translate API </li>\n",
    "<li> Google Cloud Vision API </li>\n",
    "<li> Google Natural Language API </li>\n",
    "<li> Google Cloud Speech API </li>\n",
    "</ol>\n",
    "\n",
    "Finally, because we are calling the APIs from Python (clients in many other languages are available), let's install the Python package (it's not installed by default on Datalab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 Google Inc.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
    "# import subprocess\n",
    "# retcode = subprocess.call(['pip', 'install', '-U', 'google-api-python-client'])\n",
    "# retcode = subprocess.call(['pip', 'install', '-U', 'gTTS'])\n",
    "\n",
    "# Below is for GCP only: install audio conversion tool\n",
    "# retcode = subprocess.call(['apt-get', 'update', '-y'])\n",
    "# retcode = subprocess.call(['apt-get', 'install', 'libav-tools', '-y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入需要用到的一些功能程序库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    }
   ],
   "source": [
    "import io, os, subprocess, sys, re, codecs, time, datetime, requests, itchat\n",
    "from itchat.content import *\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### GCP Machine Learning API Key\n",
    "\n",
    "First, visit <a href=\"http://console.cloud.google.com/apis\">API console</a>, choose \"Credentials\" on the left-hand menu.  Choose \"Create Credentials\" and generate an API key for your application. You should probably restrict it by IP address to prevent abuse, but for now, just  leave that field blank and delete the API key after trying out this demo.\n",
    "\n",
    "Copy-paste your API Key here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here I read in my own API_KEY from a file, which is not shared in Github repository:\n",
    "with io.open('../../../API_KEY.txt') as fp: \n",
    "    for line in fp: APIKEY = line\n",
    "\n",
    "# You need to un-comment below line and replace 'APIKEY' variable with your own GCP API key:\n",
    "# APIKEY='AIzaSyCvxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below is for Google Speech synthesis: text to voice API\n",
    "# from gtts import gTTS\n",
    "\n",
    "# Below is for  Google Speech recognition: voice to text API\n",
    "# speech_service = build('speech', 'v1', developerKey=APIKEY)\n",
    "\n",
    "# Below is for Google Language Tranlation API\n",
    "# service = build('translate', 'v2', developerKey=APIKEY)\n",
    "\n",
    "# Below is for Google Natual Language Processing API\n",
    "# nlp_service = build('language', 'v1', developerKey=APIKEY)\n",
    "nlp_service = build('language', 'v1beta2', developerKey=APIKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多媒体二进制base64码转换 (Define image pre-processing functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the base64 encoding library.\n",
    "import base64\n",
    "# Pass the image data to an encoding function.\n",
    "def encode_image(image_file):\n",
    "    with io.open(image_file, \"rb\") as image_file:\n",
    "        image_content = image_file.read()\n",
    "# Python 2\n",
    "    if sys.version_info[0] < 3:\n",
    "        return base64.b64encode(image_content)\n",
    "# Python 3\n",
    "    else:\n",
    "        return base64.b64encode(image_content).decode('utf-8')\n",
    "\n",
    "# Pass the audio data to an encoding function.\n",
    "def encode_audio(audio_file):\n",
    "    with io.open(audio_file, 'rb') as audio_file:\n",
    "        audio_content = audio_file.read()\n",
    "# Python 2\n",
    "    if sys.version_info[0] < 3:\n",
    "        return base64.b64encode(audio_content)\n",
    "# Python 3\n",
    "    else:\n",
    "        return base64.b64encode(audio_content).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器智能API接口控制参数 (Define control parameters for API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# API control parameter for Image API:\n",
    "parm_image_maxResults = 10 # max objects or faces to be extracted from image analysis\n",
    "\n",
    "# API control parameter for Language Translation API:\n",
    "parm_translation_origin_language = 'zh' # original language in text: to be overwriten by TEXT_DETECTION\n",
    "parm_translation_target_language = 'zh' # target language for translation: Chinese\n",
    "\n",
    "\n",
    "# API control parameter for 消息文字转成语音 (Speech synthesis: text to voice)\n",
    "parm_speech_synthesis_language = 'zh' # speech synthesis API 'text to voice' language\n",
    "# parm_speech_synthesis_language = 'zh-tw' # speech synthesis API 'text to voice' language\n",
    "# parm_speech_synthesis_language = 'zh-yue' # speech synthesis API 'text to voice' language\n",
    "\n",
    "# API control parameter for 语音转换成消息文字 (Speech recognition: voice to text)\n",
    "# parm_speech_recognition_language = 'en' # speech API 'voice to text' language\n",
    "parm_speech_recognition_language = 'cmn-Hans-CN' # speech API 'voice to text' language\n",
    "\n",
    "# API control parameter for 自然语言处理：语义和情感分析\n",
    "parm_nlp_extractDocumentSentiment = True \n",
    "parm_nlp_extractEntities = True \n",
    "parm_nlp_extractEntitySentiment = True # only available in v1beta2; Chinese language zh is not supported yet.\n",
    "parm_nlp_extractSyntax = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 定义一个调用自然语言处理接口的小功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running Speech API\n",
    "def KudosData_nlp(text, extractDocumentSentiment, extractEntities, extractEntitySentiment, extractSyntax): \n",
    "    # Python 2\n",
    "#     if sys.version_info[0] < 3: \n",
    "#         tts = gTTS(text=text2voice.encode('utf-8'), lang=parm_speech_synthesis_language, slow=False)\n",
    "    # Python 3\n",
    "#     else:\n",
    "#         tts = gTTS(text=text2voice, lang=parm_speech_synthesis_language, slow=False)\n",
    "        \n",
    "    request = nlp_service.documents().annotateText(body={\n",
    "                \"document\":{\n",
    "                    \"type\": \"PLAIN_TEXT\",\n",
    "                    \"content\": text\n",
    "                    },\n",
    "                \"features\": {\n",
    "                    \"extractDocumentSentiment\": extractDocumentSentiment,\n",
    "                    \"extractEntities\": extractEntities,\n",
    "                    \"extractEntitySentiment\": extractEntitySentiment, # only available in v1beta2\n",
    "                    \"extractSyntax\": extractSyntax,\n",
    "                    },\n",
    "                \"encodingType\":\"UTF8\"\n",
    "                })\n",
    "    responses = request.execute(num_retries=3)        \n",
    "    print('\\nCompeleted: NLP analysis API')\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Start of demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text4nlp = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text4nlp = 'As a data science consultant and trainer with Kudos Data, Zhan GU (Sam) engages communities and schools ' \\\n",
    "           'to help organizations making sense of their data using advanced data science , machine learning and ' \\\n",
    "           'cloud computing technologies. Inspire next generation of artificial intelligence lovers and leaders.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text4nlp = '作为酷豆数据科学的顾问和培训师，Sam Gu （白黑） 结合社群和教育资源，帮助各大公司使用先进的数据科学，'\\\n",
    "           '机器学习和云计算技术来获取数据洞见。激励下一代人工智能爱好者和领导者。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compeleted: NLP analysis API\n"
     ]
    }
   ],
   "source": [
    "responses = KudosData_nlp(text4nlp\n",
    "                            , parm_nlp_extractDocumentSentiment\n",
    "                            , parm_nlp_extractEntities\n",
    "                            , parm_nlp_extractEntitySentiment\n",
    "                            , parm_nlp_extractSyntax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 消息文字中名称实体的识别 (Name-Entity detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(responses['entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 实体 1: data science consultant ]\n",
      "[ 类别 : PERSON | 重要性 : 0.17521429 ]\n",
      "[ 褒贬度 : 0 | 语彩累积 : 0 ]\n",
      "\n",
      "[ 实体 2: trainer ]\n",
      "[ 类别 : PERSON | 重要性 : 0.17521429 ]\n",
      "[ 褒贬度 : 0 | 语彩累积 : 0 ]\n",
      "\n",
      "[ 实体 3: communities ]\n",
      "[ 类别 : PERSON | 重要性 : 0.1560961 ]\n",
      "[ 褒贬度 : 0.4 | 语彩累积 : 0.8 ]\n",
      "\n",
      "[ 实体 4: sense ]\n",
      "[ 类别 : OTHER | 重要性 : 0.06279698 ]\n",
      "[ 褒贬度 : 0 | 语彩累积 : 0 ]\n",
      "\n",
      "[ 实体 5: data ]\n",
      "[ 类别 : OTHER | 重要性 : 0.05968614 ]\n",
      "[ 褒贬度 : 0.4 | 语彩累积 : 0.4 ]\n",
      "\n",
      "[ 实体 6: Kudos Data ]\n",
      "[ 类别 : OTHER | 重要性 : 0.055152062 ]\n",
      "[ 褒贬度 : 0 | 语彩累积 : 0 ]\n",
      "\n",
      "[ 实体 7: data science ]\n",
      "[ 类别 : OTHER | 重要性 : 0.051547784 ]\n",
      "[ 褒贬度 : 0 | 语彩累积 : 0 ]\n",
      "\n",
      "[ 实体 8: schools ]\n",
      "[ 类别 : ORGANIZATION | 重要性 : 0.04895195 ]\n",
      "[ 褒贬度 : 0 | 语彩累积 : 0 ]\n",
      "\n",
      "[ 实体 9: organizations ]\n",
      "[ 类别 : ORGANIZATION | 重要性 : 0.04895195 ]\n",
      "[ 褒贬度 : 0 | 语彩累积 : 0 ]\n",
      "\n",
      "[ 实体 10: Zhan GU ]\n",
      "[ 类别 : PERSON | 重要性 : 0.041413147 ]\n",
      "[ 褒贬度 : 0 | 语彩累积 : 0 ]\n",
      "\n",
      "[ 实体 11: cloud computing technologies ]\n",
      "[ 类别 : OTHER | 重要性 : 0.033586804 ]\n",
      "[ 褒贬度 : 0 | 语彩累积 : 0 ]\n",
      "\n",
      "[ 实体 12: Sam ]\n",
      "[ 类别 : PERSON | 重要性 : 0.028737757 ]\n",
      "[ 褒贬度 : 0 | 语彩累积 : 0 ]\n",
      "\n",
      "[ 实体 13: machine learning ]\n",
      "[ 类别 : OTHER | 重要性 : 0.01472869 ]\n",
      "[ 褒贬度 : 0 | 语彩累积 : 0 ]\n",
      "\n",
      "[ 实体 14: generation ]\n",
      "[ 类别 : OTHER | 重要性 : 0.014414377 ]\n",
      "[ 褒贬度 : 0.8 | 语彩累积 : 0.8 ]\n",
      "\n",
      "[ 实体 15: lovers ]\n",
      "[ 类别 : PERSON | 重要性 : 0.011169221 ]\n",
      "[ 褒贬度 : 0.7 | 语彩累积 : 0.7 ]\n",
      "\n",
      "[ 实体 16: intelligence ]\n",
      "[ 类别 : OTHER | 重要性 : 0.011169221 ]\n",
      "[ 褒贬度 : 0.2 | 语彩累积 : 0.2 ]\n",
      "\n",
      "[ 实体 17: leaders ]\n",
      "[ 类别 : PERSON | 重要性 : 0.011169221 ]\n",
      "[ 褒贬度 : 0 | 语彩累积 : 0 ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(responses['entities'])): \n",
    "#     print(responses['entities'][i])\n",
    "    print('')\n",
    "    print(u'[ 实体 {}: {} ]\\n[ 类别 : {} | 重要性 : {} ]'.format(\n",
    "          i+1\n",
    "        , responses['entities'][i]['name']\n",
    "        , responses['entities'][i]['type']\n",
    "        , responses['entities'][i]['salience']\n",
    "    ))\n",
    "#     print(responses['entities'][i]['name'])\n",
    "#     print(responses['entities'][i]['type'])\n",
    "#     print(responses['entities'][i]['salience'])\n",
    "    if 'sentiment' in responses['entities'][i]:\n",
    "        print(u'[ 褒贬度 : {} | 语彩累积 : {} ]'.format(\n",
    "              responses['entities'][i]['sentiment']['score']\n",
    "            , responses['entities'][i]['sentiment']['magnitude']\n",
    "        ))\n",
    "#     print(responses['entities'][i]['sentiment'])\n",
    "    if responses['entities'][i]['metadata'] != {}:\n",
    "        if 'wikipedia_url' in responses['entities'][i]['metadata']:\n",
    "            print(responses['entities'][i]['metadata']['wikipedia_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 消息文字中语句的情感分析 (Sentiment analysis, Sentence level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(responses['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 语句 1: 作为酷豆数据科学的顾问和培训师，Sam Gu （白黑） 结合社群和教育资源，帮助各大公司使用先进的数据科学，机器学习和云计算技术来获取数据洞见。 ]\n",
      "[ 褒贬度 : 0.8 | 语彩累积 : 0.8 ]\n",
      "\n",
      "[ 语句 2: 激励下一代人工智能爱好者和领导者。 ]\n",
      "[ 褒贬度 : 0.2 | 语彩累积 : 0.2 ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(responses['sentences'])):\n",
    "    print('')\n",
    "    print(u'[ 语句 {}: {} ]\\n[ 褒贬度 : {} | 语彩累积 : {} ]'.format(\n",
    "          i+1\n",
    "        , responses['sentences'][i]['text']['content']\n",
    "        , responses['sentences'][i]['sentiment']['score']\n",
    "        , responses['sentences'][i]['sentiment']['magnitude']\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cloud.google.com/natural-language/docs/basics\n",
    "\n",
    "* **score 褒贬度** of the sentiment ranges between -1.0 (negative) and 1.0 (positive) and corresponds to the overall emotional leaning of the text.\n",
    "* **magnitude 语彩累积** indicates the overall strength of emotion (both positive and negative) within the given text, between 0.0 and +inf. Unlike score, magnitude is not normalized; each expression of emotion within the text (both positive and negative) contributes to the text's magnitude (so longer text blocks may have greater magnitudes).\n",
    "\n",
    "\n",
    "| Sentiment     | Sample Values |\n",
    "|:-------------:|:-------------:|\n",
    "| 明显褒义 Clearly Positive\t| \"score 褒贬度\": 0.8, \"magnitude 语彩累积\": 3.0  |\n",
    "| 明显贬义 Clearly Negative\t| \"score 褒贬度\": -0.6, \"magnitude 语彩累积\": 4.0  |\n",
    "| 中性 Neutral\t| \"score 褒贬度\": 0.1, \"magnitude 语彩累积\": 0.0  |\n",
    "| 混合 Mixed\t| \"score 褒贬度\": 0.0, \"magnitude 语彩累积\": 4.0  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 整篇消息文字的情感分析 (Sentiment analysis, Document level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(responses['documentSentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 整篇消息 语种 : zh ]\n",
      "[ 褒贬度 : 0.5 | 语彩累积: 1.1 ]\n"
     ]
    }
   ],
   "source": [
    "print(u'[ 整篇消息 语种 : {} ]\\n[ 褒贬度 : {} | 语彩累积: {} ]'.format(\n",
    "            responses['language']\n",
    "            , responses['documentSentiment']['score']\n",
    "            , responses['documentSentiment']['magnitude']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 语句的语法分析 (Syntax / Grammer analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{u'text': {u'content': u'\\u4f5c\\u4e3a', u'beginOffset': 0}, u'dependencyEdge': {u'headTokenIndex': 15, u'label': u'VMOD'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'VERB', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u4f5c\\u4e3a'}\n",
      "\n",
      "{u'text': {u'content': u'\\u9177', u'beginOffset': 6}, u'dependencyEdge': {u'headTokenIndex': 2, u'label': u'SUFF'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'NOUN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u9177'}\n",
      "\n",
      "{u'text': {u'content': u'\\u8c46', u'beginOffset': 9}, u'dependencyEdge': {u'headTokenIndex': 4, u'label': u'NN'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'AFFIX', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u8c46'}\n",
      "\n",
      "{u'text': {u'content': u'\\u6570\\u636e', u'beginOffset': 12}, u'dependencyEdge': {u'headTokenIndex': 4, u'label': u'NN'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'NOUN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u6570\\u636e'}\n",
      "\n",
      "{u'text': {u'content': u'\\u79d1\\u5b66', u'beginOffset': 18}, u'dependencyEdge': {u'headTokenIndex': 6, u'label': u'POSS'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'NOUN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u79d1\\u5b66'}\n",
      "\n",
      "{u'text': {u'content': u'\\u7684', u'beginOffset': 24}, u'dependencyEdge': {u'headTokenIndex': 4, u'label': u'PS'}, u'partOfSpeech': {u'case': u'GENITIVE', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'PRT', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u7684'}\n",
      "\n",
      "{u'text': {u'content': u'\\u987e\\u95ee', u'beginOffset': 27}, u'dependencyEdge': {u'headTokenIndex': 0, u'label': u'DOBJ'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'NOUN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u987e\\u95ee'}\n",
      "\n",
      "{u'text': {u'content': u'\\u548c', u'beginOffset': 33}, u'dependencyEdge': {u'headTokenIndex': 6, u'label': u'CC'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'CONJ', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u548c'}\n",
      "\n",
      "{u'text': {u'content': u'\\u57f9\\u8bad\\u5e08', u'beginOffset': 36}, u'dependencyEdge': {u'headTokenIndex': 6, u'label': u'CONJ'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'UNKNOWN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u57f9\\u8bad\\u5e08'}\n",
      "\n",
      "{u'text': {u'content': u'\\uff0c', u'beginOffset': 45}, u'dependencyEdge': {u'headTokenIndex': 15, u'label': u'P'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'PUNCT', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\uff0c'}\n",
      "\n",
      "{u'text': {u'content': u'Sam', u'beginOffset': 48}, u'dependencyEdge': {u'headTokenIndex': 15, u'label': u'NSUBJ'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'X', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'Sam'}\n",
      "\n",
      "{u'text': {u'content': u'Gu', u'beginOffset': 52}, u'dependencyEdge': {u'headTokenIndex': 10, u'label': u'FOREIGN'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'X', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'Gu'}\n",
      "\n",
      "{u'text': {u'content': u'\\uff08', u'beginOffset': 55}, u'dependencyEdge': {u'headTokenIndex': 13, u'label': u'P'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'PUNCT', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\uff08'}\n",
      "\n",
      "{u'text': {u'content': u'\\u767d\\u9ed1', u'beginOffset': 58}, u'dependencyEdge': {u'headTokenIndex': 10, u'label': u'APPOS'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'UNKNOWN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u767d\\u9ed1'}\n",
      "\n",
      "{u'text': {u'content': u'\\uff09', u'beginOffset': 64}, u'dependencyEdge': {u'headTokenIndex': 13, u'label': u'P'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'PUNCT', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\uff09'}\n",
      "\n",
      "{u'text': {u'content': u'\\u7ed3\\u5408', u'beginOffset': 68}, u'dependencyEdge': {u'headTokenIndex': 24, u'label': u'DEP'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'VERB', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u7ed3\\u5408'}\n",
      "\n",
      "{u'text': {u'content': u'\\u793e\\u7fa4', u'beginOffset': 74}, u'dependencyEdge': {u'headTokenIndex': 15, u'label': u'DOBJ'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'NOUN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u793e\\u7fa4'}\n",
      "\n",
      "{u'text': {u'content': u'\\u548c', u'beginOffset': 80}, u'dependencyEdge': {u'headTokenIndex': 16, u'label': u'CC'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'CONJ', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u548c'}\n",
      "\n",
      "{u'text': {u'content': u'\\u6559\\u80b2', u'beginOffset': 83}, u'dependencyEdge': {u'headTokenIndex': 19, u'label': u'NN'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'NOUN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u6559\\u80b2'}\n",
      "\n",
      "{u'text': {u'content': u'\\u8d44\\u6e90', u'beginOffset': 89}, u'dependencyEdge': {u'headTokenIndex': 16, u'label': u'CONJ'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'NOUN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u8d44\\u6e90'}\n",
      "\n",
      "{u'text': {u'content': u'\\uff0c', u'beginOffset': 95}, u'dependencyEdge': {u'headTokenIndex': 24, u'label': u'P'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'PUNCT', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\uff0c'}\n",
      "\n",
      "{u'text': {u'content': u'\\u5e2e\\u52a9', u'beginOffset': 98}, u'dependencyEdge': {u'headTokenIndex': 24, u'label': u'VMOD'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'VERB', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u5e2e\\u52a9'}\n",
      "\n",
      "{u'text': {u'content': u'\\u5404\\u5927', u'beginOffset': 104}, u'dependencyEdge': {u'headTokenIndex': 23, u'label': u'NN'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'NOUN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u5404\\u5927'}\n",
      "\n",
      "{u'text': {u'content': u'\\u516c\\u53f8', u'beginOffset': 110}, u'dependencyEdge': {u'headTokenIndex': 21, u'label': u'DOBJ'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'NOUN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u516c\\u53f8'}\n",
      "\n",
      "{u'text': {u'content': u'\\u4f7f\\u7528', u'beginOffset': 116}, u'dependencyEdge': {u'headTokenIndex': 24, u'label': u'ROOT'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'VERB', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u4f7f\\u7528'}\n",
      "\n",
      "{u'text': {u'content': u'\\u5148\\u8fdb', u'beginOffset': 122}, u'dependencyEdge': {u'headTokenIndex': 28, u'label': u'AMOD'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'ADJ', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u5148\\u8fdb'}\n",
      "\n",
      "{u'text': {u'content': u'\\u7684', u'beginOffset': 128}, u'dependencyEdge': {u'headTokenIndex': 25, u'label': u'RCMODREL'}, u'partOfSpeech': {u'case': u'RELATIVE_CASE', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'PRT', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u7684'}\n",
      "\n",
      "{u'text': {u'content': u'\\u6570\\u636e', u'beginOffset': 131}, u'dependencyEdge': {u'headTokenIndex': 28, u'label': u'NN'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'NOUN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u6570\\u636e'}\n",
      "\n",
      "{u'text': {u'content': u'\\u79d1\\u5b66', u'beginOffset': 137}, u'dependencyEdge': {u'headTokenIndex': 32, u'label': u'NSUBJ'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'NOUN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u79d1\\u5b66'}\n",
      "\n",
      "{u'text': {u'content': u'\\uff0c', u'beginOffset': 143}, u'dependencyEdge': {u'headTokenIndex': 32, u'label': u'P'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'PUNCT', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\uff0c'}\n",
      "\n",
      "{u'text': {u'content': u'\\u673a', u'beginOffset': 146}, u'dependencyEdge': {u'headTokenIndex': 31, u'label': u'SUFF'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'VERB', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u673a'}\n",
      "\n",
      "{u'text': {u'content': u'\\u5668', u'beginOffset': 149}, u'dependencyEdge': {u'headTokenIndex': 32, u'label': u'NSUBJ'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'AFFIX', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u5668'}\n",
      "\n",
      "{u'text': {u'content': u'\\u5b66\\u4e60', u'beginOffset': 152}, u'dependencyEdge': {u'headTokenIndex': 38, u'label': u'CSUBJ'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'VERB', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u5b66\\u4e60'}\n",
      "\n",
      "{u'text': {u'content': u'\\u548c', u'beginOffset': 158}, u'dependencyEdge': {u'headTokenIndex': 32, u'label': u'CC'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'CONJ', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u548c'}\n",
      "\n",
      "{u'text': {u'content': u'\\u4e91\\u8ba1\\u7b97', u'beginOffset': 161}, u'dependencyEdge': {u'headTokenIndex': 36, u'label': u'NN'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'UNKNOWN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u4e91\\u8ba1\\u7b97'}\n",
      "\n",
      "{u'text': {u'content': u'\\u6280', u'beginOffset': 170}, u'dependencyEdge': {u'headTokenIndex': 36, u'label': u'SUFF'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'NOUN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u6280'}\n",
      "\n",
      "{u'text': {u'content': u'\\u672f', u'beginOffset': 173}, u'dependencyEdge': {u'headTokenIndex': 32, u'label': u'CONJ'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'AFFIX', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u672f'}\n",
      "\n",
      "{u'text': {u'content': u'\\u6765', u'beginOffset': 176}, u'dependencyEdge': {u'headTokenIndex': 38, u'label': u'PRT'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'ADV', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u6765'}\n",
      "\n",
      "{u'text': {u'content': u'\\u83b7', u'beginOffset': 179}, u'dependencyEdge': {u'headTokenIndex': 24, u'label': u'CCOMP'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'VERB', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u83b7'}\n",
      "\n",
      "{u'text': {u'content': u'\\u53d6\\u6570', u'beginOffset': 182}, u'dependencyEdge': {u'headTokenIndex': 40, u'label': u'NSUBJ'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'UNKNOWN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u53d6\\u6570'}\n",
      "\n",
      "{u'text': {u'content': u'\\u636e', u'beginOffset': 188}, u'dependencyEdge': {u'headTokenIndex': 38, u'label': u'CCOMP'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'ADP', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u636e'}\n",
      "\n",
      "{u'text': {u'content': u'\\u6d1e', u'beginOffset': 191}, u'dependencyEdge': {u'headTokenIndex': 42, u'label': u'NSUBJ'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'UNKNOWN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u6d1e'}\n",
      "\n",
      "{u'text': {u'content': u'\\u89c1', u'beginOffset': 194}, u'dependencyEdge': {u'headTokenIndex': 40, u'label': u'PCOMP'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'VERB', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u89c1'}\n",
      "\n",
      "{u'text': {u'content': u'\\u3002', u'beginOffset': 197}, u'dependencyEdge': {u'headTokenIndex': 24, u'label': u'P'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'PUNCT', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u3002'}\n",
      "\n",
      "{u'text': {u'content': u'\\u6fc0\\u52b1', u'beginOffset': 200}, u'dependencyEdge': {u'headTokenIndex': 44, u'label': u'ROOT'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'VERB', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u6fc0\\u52b1'}\n",
      "\n",
      "{u'text': {u'content': u'\\u4e0b', u'beginOffset': 206}, u'dependencyEdge': {u'headTokenIndex': 44, u'label': u'PRT'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'ADP', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u4e0b'}\n",
      "\n",
      "{u'text': {u'content': u'\\u4e00', u'beginOffset': 209}, u'dependencyEdge': {u'headTokenIndex': 47, u'label': u'NUM'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'NUM', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u4e00'}\n",
      "\n",
      "{u'text': {u'content': u'\\u4ee3', u'beginOffset': 212}, u'dependencyEdge': {u'headTokenIndex': 51, u'label': u'UNKNOWN'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'NOUN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u4ee3'}\n",
      "\n",
      "{u'text': {u'content': u'\\u4eba\\u5de5\\u667a', u'beginOffset': 215}, u'dependencyEdge': {u'headTokenIndex': 51, u'label': u'NN'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'UNKNOWN', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u4eba\\u5de5\\u667a'}\n",
      "\n",
      "{u'text': {u'content': u'\\u80fd', u'beginOffset': 224}, u'dependencyEdge': {u'headTokenIndex': 50, u'label': u'AUX'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'VERB', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u80fd'}\n",
      "\n",
      "{u'text': {u'content': u'\\u7231\\u597d', u'beginOffset': 227}, u'dependencyEdge': {u'headTokenIndex': 51, u'label': u'SUFF'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'VERB', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u7231\\u597d'}\n",
      "\n",
      "{u'text': {u'content': u'\\u8005', u'beginOffset': 233}, u'dependencyEdge': {u'headTokenIndex': 44, u'label': u'DOBJ'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'AFFIX', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u8005'}\n",
      "\n",
      "{u'text': {u'content': u'\\u548c', u'beginOffset': 236}, u'dependencyEdge': {u'headTokenIndex': 51, u'label': u'CC'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'CONJ', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u548c'}\n",
      "\n",
      "{u'text': {u'content': u'\\u9886\\u5bfc', u'beginOffset': 239}, u'dependencyEdge': {u'headTokenIndex': 54, u'label': u'SUFF'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'VERB', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u9886\\u5bfc'}\n",
      "\n",
      "{u'text': {u'content': u'\\u8005', u'beginOffset': 245}, u'dependencyEdge': {u'headTokenIndex': 51, u'label': u'CONJ'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'AFFIX', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u8005'}\n",
      "\n",
      "{u'text': {u'content': u'\\u3002', u'beginOffset': 248}, u'dependencyEdge': {u'headTokenIndex': 44, u'label': u'P'}, u'partOfSpeech': {u'case': u'CASE_UNKNOWN', u'reciprocity': u'RECIPROCITY_UNKNOWN', u'mood': u'MOOD_UNKNOWN', u'form': u'FORM_UNKNOWN', u'gender': u'GENDER_UNKNOWN', u'number': u'NUMBER_UNKNOWN', u'person': u'PERSON_UNKNOWN', u'tag': u'PUNCT', u'tense': u'TENSE_UNKNOWN', u'aspect': u'ASPECT_UNKNOWN', u'proper': u'NOT_PROPER', u'voice': u'VOICE_UNKNOWN'}, u'lemma': u'\\u3002'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(responses['tokens'])): \n",
    "    print('')\n",
    "    print(responses['tokens'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### End of demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义一个输出NLP分析结果，用于回复微信消息的小功能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KudosData_nlp_generate_reply(responses):\n",
    "    nlp_reply = u'[ NLP 自然语言处理结果 ]'\n",
    "    \n",
    "    # * 整篇消息文字的情感分析 (Sentiment analysis, Document level)\n",
    "    nlp_reply += '\\n'\n",
    "    nlp_reply += '\\n' + u'[ 整篇消息 语种 : {} ]\\n[ 褒贬度 : {} | 语彩累积: {} ]'.format(\n",
    "            responses['language']\n",
    "            , responses['documentSentiment']['score']\n",
    "            , responses['documentSentiment']['magnitude']\n",
    "        )\n",
    "\n",
    "    # * 消息文字中语句的情感分析 (Sentiment analysis, Sentence level)           \n",
    "    nlp_reply += '\\n'\n",
    "    for i in range(len(responses['sentences'])):\n",
    "        nlp_reply += '\\n' + u'[ 语句 {}: {} ]\\n[ 褒贬度 : {} | 语彩累积 : {} ]'.format(\n",
    "              i+1\n",
    "            , responses['sentences'][i]['text']['content']\n",
    "            , responses['sentences'][i]['sentiment']['score']\n",
    "            , responses['sentences'][i]['sentiment']['magnitude']\n",
    "        )\n",
    "                \n",
    "    # * 消息文字中名称实体的识别 (Name-Entity detection)\n",
    "    nlp_reply += '\\n'\n",
    "    for i in range(len(responses['entities'])): \n",
    "        nlp_reply += '\\n' + u'[ 实体 {}: {} ]\\n[ 类别 : {} | 重要性 : {} ]'.format(\n",
    "              i+1\n",
    "            , responses['entities'][i]['name']\n",
    "            , responses['entities'][i]['type']\n",
    "            , responses['entities'][i]['salience']\n",
    "        )\n",
    "        if 'sentiment' in responses['entities'][i]:\n",
    "            nlp_reply += '\\n' + u'[ 褒贬度 : {} | 语彩累积 : {} ]'.format(\n",
    "                  responses['entities'][i]['sentiment']['score']\n",
    "                , responses['entities'][i]['sentiment']['magnitude']\n",
    "            )\n",
    "        if responses['entities'][i]['metadata'] != {}:\n",
    "            if 'wikipedia_url' in responses['entities'][i]['metadata']:\n",
    "                nlp_reply += '\\n' + responses['entities'][i]['metadata']['wikipedia_url']\n",
    "                           \n",
    "    # * 语句的语法分析 (Syntax / Grammer analysis)\n",
    "#     nlp_reply += '\\n'\n",
    "#     for i in range(len(responses['tokens'])): \n",
    "#         nlp_reply += '\\n' + str(responses['tokens'][i])\n",
    "    \n",
    "    return nlp_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ NLP 自然语言处理结果 ]\n",
      "\n",
      "[ 整篇消息 语种 : zh ]\n",
      "[ 褒贬度 : 0.5 | 语彩累积: 1.1 ]\n",
      "\n",
      "[ 语句 1: 作为酷豆数据科学的顾问和培训师，Sam Gu （白黑） 结合社群和教育资源，帮助各大公司使用先进的数据科学，机器学习和云计算技术来获取数据洞见。 ]\n",
      "[ 褒贬度 : 0.8 | 语彩累积 : 0.8 ]\n",
      "[ 语句 2: 激励下一代人工智能爱好者和领导者。 ]\n",
      "[ 褒贬度 : 0.2 | 语彩累积 : 0.2 ]\n",
      "\n",
      "[ 实体 1: 酷豆数据科学 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.195719 ]\n",
      "https://en.wikipedia.org/wiki/Data_science\n",
      "[ 实体 2: 顾问 ]\n",
      "[ 类别 : PERSON | 重要性 : 0.12852265 ]\n",
      "[ 实体 3: Sam Gu ]\n",
      "[ 类别 : PERSON | 重要性 : 0.12153177 ]\n",
      "[ 实体 4: 培训师 ]\n",
      "[ 类别 : PERSON | 重要性 : 0.105539404 ]\n",
      "[ 实体 5: 白黑 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.105539404 ]\n",
      "[ 实体 6: 云计算技术 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.07785424 ]\n",
      "[ 实体 7: 数据科学 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.06426745 ]\n",
      "[ 实体 8: 机器 ]\n",
      "[ 类别 : CONSUMER_GOOD | 重要性 : 0.052090105 ]\n",
      "[ 实体 9: 各大公司 ]\n",
      "[ 类别 : ORGANIZATION | 重要性 : 0.038682967 ]\n",
      "[ 实体 10: 社群 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.031572923 ]\n",
      "[ 实体 11: 教育资源 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.031572923 ]\n",
      "[ 实体 12: 人工智能爱好者 ]\n",
      "[ 类别 : PERSON | 重要性 : 0.023553587 ]\n",
      "[ 实体 13: 领导者 ]\n",
      "[ 类别 : PERSON | 重要性 : 0.023553587 ]\n"
     ]
    }
   ],
   "source": [
    "print(KudosData_nlp_generate_reply(responses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用微信App扫QR码图片来自动登录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itchat.auto_login(hotReload=True) # hotReload=True: 退出程序后暂存登陆状态。即使程序关闭，一定时间内重新开启也可以不用重新扫码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtain my own Nick Name\n",
    "MySelf = itchat.search_friends()\n",
    "NickName4RegEx = '@' + MySelf['NickName'] + '\\s*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 自动j进行自然语言分析，以文本形式返回处理结果：\n",
    "# @itchat.msg_register(TEXT, isGroupChat=True)\n",
    "@itchat.msg_register(TEXT)\n",
    "def text_reply(msg):\n",
    "#     if msg['isAt']:\n",
    "        text4nlp = msg['Content']\n",
    "        # call NLP API:\n",
    "        nlp_responses = KudosData_nlp(text4nlp\n",
    "                            , parm_nlp_extractDocumentSentiment\n",
    "                            , parm_nlp_extractEntities\n",
    "                            , parm_nlp_extractEntitySentiment\n",
    "                            , parm_nlp_extractSyntax)\n",
    "        # Format NLP results:\n",
    "        nlp_reply = KudosData_nlp_generate_reply(nlp_responses)\n",
    "        print(nlp_reply)\n",
    "        return nlp_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 在群里，如果收到 @ 自己的文字信息，会自动j进行自然语言分析，以文本形式返回处理结果：\n",
    "@itchat.msg_register(TEXT, isGroupChat=True)\n",
    "def text_reply(msg):\n",
    "    if msg['isAt']:\n",
    "        text4nlp = re.sub(NickName4RegEx, '', msg['Content'])\n",
    "        # call NLP API:\n",
    "        nlp_responses = KudosData_nlp(text4nlp\n",
    "                            , parm_nlp_extractDocumentSentiment\n",
    "                            , parm_nlp_extractEntities\n",
    "                            , parm_nlp_extractEntitySentiment\n",
    "                            , parm_nlp_extractSyntax)\n",
    "        # Format NLP results:\n",
    "        nlp_reply = KudosData_nlp_generate_reply(nlp_responses)\n",
    "        print(nlp_reply)\n",
    "        return nlp_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start auto replying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compeleted: NLP analysis API\n",
      "[ NLP 自然语言处理结果 ]\n",
      "\n",
      "[ 整篇消息 语种 : zh ]\n",
      "[ 褒贬度 : 0.4 | 语彩累积: 1.4 ]\n",
      "\n",
      "[ 语句 1: 在 23 日的首轮比赛中，AlphaGo 以四分之一子的优势，击败了世界第一人类围棋手柯洁。 ]\n",
      "[ 褒贬度 : 0.5 | 语彩累积 : 0.5 ]\n",
      "[ 语句 2: 赢得比赛后，这场人机大战引起了人们广泛的关注和讨论。 ]\n",
      "[ 褒贬度 : 0.4 | 语彩累积 : 0.4 ]\n",
      "[ 语句 3: DeepMind 也在赛后分析解读了 AlphaGo 背后的技术，表示当前版本 AlphaGo Master 的棋力，较与李世乭对弈的 AlphaGo 版本有三子提升，就连柯洁本人也在微博上表达了自己的「震惊」 ]\n",
      "[ 褒贬度 : 0.4 | 语彩累积 : 0.4 ]\n",
      "\n",
      "[ 实体 1: AlphaGo ]\n",
      "[ 类别 : UNKNOWN | 重要性 : 0.24711089 ]\n",
      "https://en.wikipedia.org/wiki/AlphaGo\n",
      "[ 实体 2: 首轮比赛 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.112002544 ]\n",
      "[ 实体 3: 优势 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.091613464 ]\n",
      "[ 实体 4: 世界 ]\n",
      "[ 类别 : LOCATION | 重要性 : 0.091613464 ]\n",
      "[ 实体 5: 人类围棋手 ]\n",
      "[ 类别 : PERSON | 重要性 : 0.091613464 ]\n",
      "[ 实体 6: AlphaGo Master ]\n",
      "[ 类别 : CONSUMER_GOOD | 重要性 : 0.05466258 ]\n",
      "[ 实体 7: 柯洁 ]\n",
      "[ 类别 : PERSON | 重要性 : 0.037837576 ]\n",
      "https://en.wikipedia.org/wiki/Ke_Jie\n",
      "[ 实体 8: 版本 ]\n",
      "[ 类别 : CONSUMER_GOOD | 重要性 : 0.032528047 ]\n",
      "[ 实体 9: 棋力 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.024161054 ]\n",
      "[ 实体 10: 人们 ]\n",
      "[ 类别 : PERSON | 重要性 : 0.023656383 ]\n",
      "[ 实体 11: 关注 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.023656383 ]\n",
      "[ 实体 12: 讨论 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.023656383 ]\n",
      "[ 实体 13: DeepMind ]\n",
      "[ 类别 : PERSON | 重要性 : 0.021985013 ]\n",
      "https://en.wikipedia.org/wiki/DeepMind\n",
      "[ 实体 14: 技术 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.020660846 ]\n",
      "[ 实体 15: 版本 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.017822478 ]\n",
      "[ 实体 16: 微博 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.012009602 ]\n",
      "\n",
      "Compeleted: NLP analysis API\n",
      "[ NLP 自然语言处理结果 ]\n",
      "\n",
      "[ 整篇消息 语种 : en ]\n",
      "[ 褒贬度 : 0.8 | 语彩累积: 0.8 ]\n",
      "\n",
      "[ 语句 1: Hi, nice to meet you. ]\n",
      "[ 褒贬度 : 0.8 | 语彩累积 : 0.8 ]\n",
      "\n",
      "\n",
      "Compeleted: NLP analysis API\n",
      "[ NLP 自然语言处理结果 ]\n",
      "\n",
      "[ 整篇消息 语种 : zh ]\n",
      "[ 褒贬度 : 0.4 | 语彩累积: 1.4 ]\n",
      "\n",
      "[ 语句 1: 在 23 日的首轮比赛中，AlphaGo 以四分之一子的优势，击败了世界第一人类围棋手柯洁。 ]\n",
      "[ 褒贬度 : 0.5 | 语彩累积 : 0.5 ]\n",
      "[ 语句 2: 赢得比赛后，这场人机大战引起了人们广泛的关注和讨论。 ]\n",
      "[ 褒贬度 : 0.4 | 语彩累积 : 0.4 ]\n",
      "[ 语句 3: DeepMind 也在赛后分析解读了 AlphaGo 背后的技术，表示当前版本 AlphaGo Master 的棋力，较与李世乭对弈的 AlphaGo 版本有三子提升，就连柯洁本人也在微博上表达了自己的「震惊」 ]\n",
      "[ 褒贬度 : 0.4 | 语彩累积 : 0.4 ]\n",
      "\n",
      "[ 实体 1: AlphaGo ]\n",
      "[ 类别 : UNKNOWN | 重要性 : 0.24711089 ]\n",
      "https://en.wikipedia.org/wiki/AlphaGo\n",
      "[ 实体 2: 首轮比赛 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.112002544 ]\n",
      "[ 实体 3: 优势 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.091613464 ]\n",
      "[ 实体 4: 世界 ]\n",
      "[ 类别 : LOCATION | 重要性 : 0.091613464 ]\n",
      "[ 实体 5: 人类围棋手 ]\n",
      "[ 类别 : PERSON | 重要性 : 0.091613464 ]\n",
      "[ 实体 6: AlphaGo Master ]\n",
      "[ 类别 : CONSUMER_GOOD | 重要性 : 0.05466258 ]\n",
      "[ 实体 7: 柯洁 ]\n",
      "[ 类别 : PERSON | 重要性 : 0.037837576 ]\n",
      "https://en.wikipedia.org/wiki/Ke_Jie\n",
      "[ 实体 8: 版本 ]\n",
      "[ 类别 : CONSUMER_GOOD | 重要性 : 0.032528047 ]\n",
      "[ 实体 9: 棋力 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.024161054 ]\n",
      "[ 实体 10: 人们 ]\n",
      "[ 类别 : PERSON | 重要性 : 0.023656383 ]\n",
      "[ 实体 11: 关注 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.023656383 ]\n",
      "[ 实体 12: 讨论 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.023656383 ]\n",
      "[ 实体 13: DeepMind ]\n",
      "[ 类别 : PERSON | 重要性 : 0.021985013 ]\n",
      "https://en.wikipedia.org/wiki/DeepMind\n",
      "[ 实体 14: 技术 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.020660846 ]\n",
      "[ 实体 15: 版本 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.017822478 ]\n",
      "[ 实体 16: 微博 ]\n",
      "[ 类别 : OTHER | 重要性 : 0.012009602 ]\n",
      "\n",
      "Compeleted: NLP analysis API\n",
      "[ NLP 自然语言处理结果 ]\n",
      "\n",
      "[ 整篇消息 语种 : en ]\n",
      "[ 褒贬度 : 0.8 | 语彩累积: 0.8 ]\n",
      "\n",
      "[ 语句 1: Hi, nice to meet you. ]\n",
      "[ 褒贬度 : 0.8 | 语彩累积 : 0.8 ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bye~\n"
     ]
    }
   ],
   "source": [
    "itchat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ItchatReturnValue: {'BaseResponse': {'RawMsg': 'logout successfully.', 'ErrMsg': '请求成功', 'Ret': 0}}>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG OUT!\n"
     ]
    }
   ],
   "source": [
    "# interupt kernel, then logout\n",
    "itchat.logout() # 安全退出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四课：自然语言处理：语义和情感分析\n",
    "### Lesson 4: Natural Language Processing 2\n",
    "* 消息文字中名称实体的识别 (Name-Entity detection)\n",
    "* 消息文字中语句的情感分析 (Sentiment analysis, Sentence level)\n",
    "* 整篇消息文字的情感分析 (Sentiment analysis, Document level)\n",
    "* 语句的语法分析 (Syntax / Grammer analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下一课是:\n",
    "### 第五课：视频识别和处理\n",
    "### Lesson 5: Video Recognition & Processing\n",
    "* 识别视频消息中的物体名字 (Recognize objects in video)\n",
    "* 识别视频的场景 (Detect scenery in video)\n",
    "* 直接搜索视频内容 (Search content in video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://www.kudosdata.com/wp-content/uploads/2016/11/cropped-KudosLogo1.png' width=30% style=\"float: right;\">\n",
    "<img src='reference/WeChat_SamGu_QR.png' width=10% style=\"float: left;\">\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
