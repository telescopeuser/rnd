{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何使用和开发微信聊天机器人的系列教程\n",
    "# A workshop to develop & use an intelligent and interactive chat-bot in WeChat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WeChat is a popular social media app, which has more than 800 million monthly active users.\n",
    "\n",
    "<img src='http://www.kudosdata.com/wp-content/uploads/2016/11/cropped-KudosLogo1.png' width=30% style=\"float: right;\">\n",
    "<img src='reference/WeChat_SamGu_QR.png' width=10% style=\"float: right;\">\n",
    "\n",
    "### http://www.KudosData.com\n",
    "\n",
    "by: Sam.Gu@KudosData.com\n",
    "\n",
    "\n",
    "May 2017 ========== Scan the QR code to become trainer's friend in WeChat ========>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四课：自然语言处理：语义和情感分析\n",
    "### Lesson 4: Natural Language Processing 2\n",
    "* 消息文字中名称实体的识别 (Name-Entity detection)\n",
    "* 消息文字中语句的情感分析 (Sentiment analysis, Sentence level)\n",
    "* 整篇消息文字的情感分析 (Sentiment analysis, Document level)\n",
    "* 语句的语法分析 (Syntax / Grammer analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flag to indicate the environment to run this program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parm_runtime_env_GCP = True\n",
    "parm_runtime_env_GCP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using Google Cloud Platform's Machine Learning APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the same API console, choose \"Dashboard\" on the left-hand menu and \"Enable API\".\n",
    "\n",
    "Enable the following APIs for your project (search for them) if they are not already enabled:\n",
    "<ol>\n",
    "<li> Google Translate API </li>\n",
    "<li> Google Cloud Vision API </li>\n",
    "<li> Google Natural Language API </li>\n",
    "<li> Google Cloud Speech API </li>\n",
    "</ol>\n",
    "\n",
    "Finally, because we are calling the APIs from Python (clients in many other languages are available), let's install the Python package (it's not installed by default on Datalab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 Google Inc.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
    "# import subprocess\n",
    "# retcode = subprocess.call(['pip', 'install', '-U', 'google-api-python-client'])\n",
    "# retcode = subprocess.call(['pip', 'install', '-U', 'gTTS'])\n",
    "\n",
    "# Below is for GCP only: install audio conversion tool\n",
    "# retcode = subprocess.call(['apt-get', 'update', '-y'])\n",
    "# retcode = subprocess.call(['apt-get', 'install', 'libav-tools', '-y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入需要用到的一些功能程序库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, subprocess, sys, re, codecs, time, datetime, requests, itchat\n",
    "from itchat.content import *\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### GCP Machine Learning API Key\n",
    "\n",
    "First, visit <a href=\"http://console.cloud.google.com/apis\">API console</a>, choose \"Credentials\" on the left-hand menu.  Choose \"Create Credentials\" and generate an API key for your application. You should probably restrict it by IP address to prevent abuse, but for now, just  leave that field blank and delete the API key after trying out this demo.\n",
    "\n",
    "Copy-paste your API Key here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I read in my own API_KEY from a file, which is not shared in Github repository:\n",
    "with io.open('../../../API_KEY.txt') as fp: \n",
    "    for line in fp: APIKEY = line\n",
    "\n",
    "# You need to un-comment below line and replace 'APIKEY' variable with your own GCP API key:\n",
    "# APIKEY='AIzaSyCvxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below is for Google Speech synthesis: text to voice API\n",
    "# from gtts import gTTS\n",
    "\n",
    "# Below is for  Google Speech recognition: voice to text API\n",
    "# speech_service = build('speech', 'v1', developerKey=APIKEY)\n",
    "\n",
    "# Below is for Google Language Tranlation API\n",
    "# service = build('translate', 'v2', developerKey=APIKEY)\n",
    "\n",
    "# Below is for Google Natual Language Processing API\n",
    "# nlp_service = build('language', 'v1', developerKey=APIKEY)\n",
    "nlp_service = build('language', 'v1beta2', developerKey=APIKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'As a data science consultant and trainer with Kudos Data, Zhan GU (Sam) engages communities and schools' \\\n",
    "            'to help organizations making sense of their data using advanced data science , machine learning and' \\\n",
    "            'cloud computing technologies. Inspire next generation of artificial intelligence lovers and leaders.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "message = '作为酷豆数据科学的顾问和培训师，Sam Gu联合社群和教育资源，帮助各大公司使用先进的数据科学，'\\\n",
    "            '机器学习和云计算技术来获取数据洞见。激励下一代人工智能爱好者和领导者。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 消息文字中名称实体的识别 (Name-Entity detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(responses['entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(responses['entities'])): \n",
    "#     print(responses['entities'][i])\n",
    "    print('')\n",
    "    print('[ Entity {}: {} ]\\n[ Type : {} | Importance : {} ]'.format(\n",
    "          i+1\n",
    "        , responses['entities'][i]['name']\n",
    "        , responses['entities'][i]['type']\n",
    "        , responses['entities'][i]['salience']\n",
    "    ))\n",
    "#     print(responses['entities'][i]['name'])\n",
    "#     print(responses['entities'][i]['type'])\n",
    "#     print(responses['entities'][i]['salience'])\n",
    "    if 'sentiment' in responses['entities'][i]:\n",
    "        print('[ Sentiment : {} | Magnitude : {} ]'.format(\n",
    "              responses['entities'][i]['sentiment']['score']\n",
    "            , responses['entities'][i]['sentiment']['magnitude']\n",
    "        ))\n",
    "#     print(responses['entities'][i]['sentiment'])\n",
    "    if responses['entities'][i]['metadata'] != {}:\n",
    "        if 'wikipedia_url' in responses['entities'][i]['metadata']:\n",
    "            print(responses['entities'][i]['metadata']['wikipedia_url'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 消息文字中语句的情感分析 (Sentiment analysis, Sentence level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(responses['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(responses['sentences'])):\n",
    "    print('')\n",
    "    print('[ Sentence {}: {} ]\\n[ Sentiment : {} | Magnitude : {} ]'.format(\n",
    "          i+1\n",
    "        , responses['sentences'][i]['text']['content']\n",
    "        , responses['sentences'][i]['sentiment']['score']\n",
    "        , responses['sentences'][i]['sentiment']['magnitude']\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 整篇消息文字的情感分析 (Sentiment analysis, Document level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(responses['documentSentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[ Overall Message | Sentiment: {} | Magnitude: {} ]'.format(\n",
    "          responses['documentSentiment']['score']\n",
    "        , responses['documentSentiment']['magnitude']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 语句的语法分析 (Syntax / Grammer analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(responses['tokens'])): \n",
    "    print('')\n",
    "    print(responses['tokens'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 识别消息文字语种："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(responses['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多媒体二进制base64码转换 (Define image pre-processing functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the base64 encoding library.\n",
    "import base64\n",
    "# Pass the image data to an encoding function.\n",
    "def encode_image(image_file):\n",
    "    with io.open(image_file, \"rb\") as image_file:\n",
    "        image_content = image_file.read()\n",
    "# Python 2\n",
    "    if sys.version_info[0] < 3:\n",
    "        return base64.b64encode(image_content)\n",
    "# Python 3\n",
    "    else:\n",
    "        return base64.b64encode(image_content).decode('utf-8')\n",
    "\n",
    "# Pass the audio data to an encoding function.\n",
    "def encode_audio(audio_file):\n",
    "    with io.open(audio_file, 'rb') as audio_file:\n",
    "        audio_content = audio_file.read()\n",
    "# Python 2\n",
    "    if sys.version_info[0] < 3:\n",
    "        return base64.b64encode(audio_content)\n",
    "# Python 3\n",
    "    else:\n",
    "        return base64.b64encode(audio_content).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器智能API接口控制参数 (Define control parameters for API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# API control parameter for Image API:\n",
    "parm_image_maxResults = 10 # max objects or faces to be extracted from image analysis\n",
    "\n",
    "# API control parameter for Language Translation API:\n",
    "parm_translation_origin_language = 'zh' # original language in text: to be overwriten by TEXT_DETECTION\n",
    "parm_translation_target_language = 'zh' # target language for translation: Chinese\n",
    "\n",
    "\n",
    "# API control parameter for 消息文字转成语音 (Speech synthesis: text to voice)\n",
    "parm_speech_synthesis_language = 'zh' # speech synthesis API 'text to voice' language\n",
    "# parm_speech_synthesis_language = 'zh-tw' # speech synthesis API 'text to voice' language\n",
    "# parm_speech_synthesis_language = 'zh-yue' # speech synthesis API 'text to voice' language\n",
    "\n",
    "# API control parameter for 语音转换成消息文字 (Speech recognition: voice to text)\n",
    "# parm_speech_recognition_language = 'en' # speech API 'voice to text' language\n",
    "parm_speech_recognition_language = 'cmn-Hans-CN' # speech API 'voice to text' language\n",
    "\n",
    "# API control parameter for 自然语言处理：语义和情感分析\n",
    "parm_nlp_extractDocumentSentiment = True \n",
    "parm_nlp_extractEntities = True \n",
    "parm_nlp_extractEntitySentiment = False # only available in v1beta2; Chinese language zh is not supported yet.\n",
    "parm_nlp_extractSyntax = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 定义一个调用自然语言处理接口的小功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running Speech API\n",
    "def KudosData_nlp(text, extractDocumentSentiment, extractEntities, extractEntitySentiment, extractSyntax): \n",
    "    # Python 2\n",
    "#     if sys.version_info[0] < 3: \n",
    "#         tts = gTTS(text=text2voice.encode('utf-8'), lang=parm_speech_synthesis_language, slow=False)\n",
    "    # Python 3\n",
    "#     else:\n",
    "#         tts = gTTS(text=text2voice, lang=parm_speech_synthesis_language, slow=False)\n",
    "        \n",
    "    request = nlp_service.documents().annotateText(body={\n",
    "                \"document\":{\n",
    "                    \"type\": \"PLAIN_TEXT\",\n",
    "                    \"content\": text\n",
    "                    },\n",
    "                \"features\": {\n",
    "                    \"extractDocumentSentiment\": extractDocumentSentiment,\n",
    "                    \"extractEntities\": extractEntities,\n",
    "                    \"extractEntitySentiment\": extractEntitySentiment, # only available in v1beta2\n",
    "                    \"extractSyntax\": extractSyntax,\n",
    "                    },\n",
    "                \"encodingType\":\"UTF8\"\n",
    "                })\n",
    "    responses = request.execute(num_retries=3)        \n",
    "    print('\\nCompeleted: NLP analysis API')\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "message = '作为酷豆数据科学的顾问和培训师，Sam Gu （白黑） 结合社群和教育资源，帮助各大公司使用先进的数据科学，'\\\n",
    "          '机器学习和云计算技术来获取数据洞见。激励下一代人工智能爱好者和领导者。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses = KudosData_nlp(message\n",
    "                            , parm_nlp_extractDocumentSentiment\n",
    "                            , parm_nlp_extractEntities\n",
    "                            , parm_nlp_extractEntitySentiment\n",
    "                            , parm_nlp_extractSyntax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 消息文字中名称实体的识别 (Name-Entity detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(responses['entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(responses['entities'])): \n",
    "#     print(responses['entities'][i])\n",
    "    print('')\n",
    "    print('[ 实体 {}: {} ]\\n[ 类别 : {} | 重要性 : {} ]'.format(\n",
    "          i+1\n",
    "        , responses['entities'][i]['name']\n",
    "        , responses['entities'][i]['type']\n",
    "        , responses['entities'][i]['salience']\n",
    "    ))\n",
    "#     print(responses['entities'][i]['name'])\n",
    "#     print(responses['entities'][i]['type'])\n",
    "#     print(responses['entities'][i]['salience'])\n",
    "    if 'sentiment' in responses['entities'][i]:\n",
    "        print('[ 褒贬度 : {} | 语彩累积 : {} ]'.format(\n",
    "              responses['entities'][i]['sentiment']['score']\n",
    "            , responses['entities'][i]['sentiment']['magnitude']\n",
    "        ))\n",
    "#     print(responses['entities'][i]['sentiment'])\n",
    "    if responses['entities'][i]['metadata'] != {}:\n",
    "        if 'wikipedia_url' in responses['entities'][i]['metadata']:\n",
    "            print(responses['entities'][i]['metadata']['wikipedia_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 消息文字中语句的情感分析 (Sentiment analysis, Sentence level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(responses['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(responses['sentences'])):\n",
    "    print('')\n",
    "    print('[ 语句 {}: {} ]\\n[ 褒贬度 : {} | 语彩累积 : {} ]'.format(\n",
    "          i+1\n",
    "        , responses['sentences'][i]['text']['content']\n",
    "        , responses['sentences'][i]['sentiment']['score']\n",
    "        , responses['sentences'][i]['sentiment']['magnitude']\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cloud.google.com/natural-language/docs/basics\n",
    "\n",
    "* **score 褒贬度** of the sentiment ranges between -1.0 (negative) and 1.0 (positive) and corresponds to the overall emotional leaning of the text.\n",
    "* **magnitude 语彩累积** indicates the overall strength of emotion (both positive and negative) within the given text, between 0.0 and +inf. Unlike score, magnitude is not normalized; each expression of emotion within the text (both positive and negative) contributes to the text's magnitude (so longer text blocks may have greater magnitudes).\n",
    "\n",
    "\n",
    "| Sentiment     | Sample Values |\n",
    "|:-------------:|:-------------:|\n",
    "| 明显褒义 Clearly Positive\t| \"score 褒贬度\": 0.8, \"magnitude 语彩累积\": 3.0  |\n",
    "| 明显贬义 Clearly Negative\t| \"score 褒贬度\": -0.6, \"magnitude 语彩累积\": 4.0  |\n",
    "| 中性 Neutral\t| \"score 褒贬度\": 0.1, \"magnitude 语彩累积\": 0.0  |\n",
    "| 混合 Mixed\t| \"score 褒贬度\": 0.0, \"magnitude 语彩累积\": 4.0  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 整篇消息文字的情感分析 (Sentiment analysis, Document level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(responses['documentSentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[ 整篇消息 语种 : {} ]\\n[ 褒贬度 : {} | 语彩累积: {} ]'.format(\n",
    "            responses['language']\n",
    "            , responses['documentSentiment']['score']\n",
    "            , responses['documentSentiment']['magnitude']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 语句的语法分析 (Syntax / Grammer analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(responses['tokens'])): \n",
    "    print('')\n",
    "    print(responses['tokens'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义一个输出NLP分析结果，用于回复微信消息的小功能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KudosData_nlp_generate_reply(nlp_api_response):\n",
    "    nlp_reply = '[ NLP 自然语言处理结果 ]'\n",
    "    \n",
    "    # * 整篇消息文字的情感分析 (Sentiment analysis, Document level)\n",
    "    nlp_reply += '\\n'\n",
    "    nlp_reply += '\\n' + '[ 整篇消息 语种 : {} ]\\n[ 褒贬度 : {} | 语彩累积: {} ]'.format(\n",
    "            responses['language']\n",
    "            , responses['documentSentiment']['score']\n",
    "            , responses['documentSentiment']['magnitude']\n",
    "        )\n",
    "\n",
    "    # * 消息文字中语句的情感分析 (Sentiment analysis, Sentence level)           \n",
    "    nlp_reply += '\\n'\n",
    "    for i in range(len(responses['sentences'])):\n",
    "        nlp_reply += '\\n' + '[ 语句 {}: {} ]\\n[ 褒贬度 : {} | 语彩累积 : {} ]'.format(\n",
    "              i+1\n",
    "            , responses['sentences'][i]['text']['content']\n",
    "            , responses['sentences'][i]['sentiment']['score']\n",
    "            , responses['sentences'][i]['sentiment']['magnitude']\n",
    "        )\n",
    "                \n",
    "    # * 消息文字中名称实体的识别 (Name-Entity detection)\n",
    "    nlp_reply += '\\n'\n",
    "    for i in range(len(responses['entities'])): \n",
    "        nlp_reply += '\\n' + '[ 实体 {}: {} ]\\n[ 类别 : {} | 重要性 : {} ]'.format(\n",
    "              i+1\n",
    "            , responses['entities'][i]['name']\n",
    "            , responses['entities'][i]['type']\n",
    "            , responses['entities'][i]['salience']\n",
    "        )\n",
    "        if 'sentiment' in responses['entities'][i]:\n",
    "            nlp_reply += '\\n' + '[ 褒贬度 : {} | 语彩累积 : {} ]'.format(\n",
    "                  responses['entities'][i]['sentiment']['score']\n",
    "                , responses['entities'][i]['sentiment']['magnitude']\n",
    "            )\n",
    "        if responses['entities'][i]['metadata'] != {}:\n",
    "            if 'wikipedia_url' in responses['entities'][i]['metadata']:\n",
    "                nlp_reply += '\\n' + responses['entities'][i]['metadata']['wikipedia_url']\n",
    "                           \n",
    "    # * 语句的语法分析 (Syntax / Grammer analysis)\n",
    "#     nlp_reply += '\\n'\n",
    "#     for i in range(len(responses['tokens'])): \n",
    "#         nlp_reply += '\\n' + str(responses['tokens'][i])\n",
    "    \n",
    "    return nlp_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_reply = KudosData_nlp_generate_reply(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlp_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用微信App扫QR码图片来自动登录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itchat.auto_login(hotReload=True) # hotReload=True: 退出程序后暂存登陆状态。即使程序关闭，一定时间内重新开启也可以不用重新扫码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtain my own Nick Name\n",
    "MySelf = itchat.search_friends()\n",
    "NickName4RegEx = '@' + MySelf['NickName'] + '\\s*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 消息文字转成语音 (Speech synthesis: text to voice)\n",
    "\n",
    "# 在群里，如果收到 @ 自己的文字信息，会自动将文字转换成语音，再以 mp3 文件方式发送回复：\n",
    "@itchat.msg_register(TEXT, isGroupChat=True)\n",
    "def text_to_voice_reply(msg):\n",
    "    if msg['isAt']:\n",
    "        # Remove my own Nick Name from message:\n",
    "        text2voice = re.sub(NickName4RegEx, '', msg['Content'])\n",
    "        text2voiceMP3name = KudosData_text_to_voice(text2voice)\n",
    "        itchat.send('@%s@%s' % ('fil', text2voiceMP3name), msg['FromUserName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 在群里，如果收到 @ 自己的文字信息，会自动j进行自然语言分析，以文本形式返回处理结果：\n",
    "@itchat.msg_register(TEXT, isGroupChat=True)\n",
    "def text_reply(msg):\n",
    "    if msg['isAt']:\n",
    "        text4nlp = re.sub(NickName4RegEx, '', msg['Content'])\n",
    "        # call NLP API:\n",
    "        nlp_responses = KudosData_nlp(message\n",
    "                            , parm_nlp_extractDocumentSentiment\n",
    "                            , parm_nlp_extractEntities\n",
    "                            , parm_nlp_extractEntitySentiment\n",
    "                            , parm_nlp_extractSyntax)\n",
    "        # Format NLP results:\n",
    "        nlp_reply = KudosData_nlp_generate_reply(nlp_responses)\n",
    "        print(nlp_reply)\n",
    "        return nlp_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "itchat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interupt kernel, then logout\n",
    "itchat.logout() # 安全退出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四课：自然语言处理：语义和情感分析\n",
    "### Lesson 4: Natural Language Processing 2\n",
    "* 消息文字中名称实体的识别 (Name-Entity detection)\n",
    "* 消息文字中语句的情感分析 (Sentiment analysis, Sentence level)\n",
    "* 整篇消息文字的情感分析 (Sentiment analysis, Document level)\n",
    "* 语句的语法分析 (Syntax / Grammer analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下一课是:\n",
    "### 第五课：视频识别和处理\n",
    "### Lesson 5: Video Recognition & Processing\n",
    "* 识别视频消息中的物体名字 (Recognize objects in video)\n",
    "* 识别视频的场景 (Detect scenery in video)\n",
    "* 直接搜索视频内容 (Search content in video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://www.kudosdata.com/wp-content/uploads/2016/11/cropped-KudosLogo1.png' width=30% style=\"float: right;\">\n",
    "<img src='reference/WeChat_SamGu_QR.png' width=10% style=\"float: left;\">\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
